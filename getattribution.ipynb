{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0'\n",
    "\n",
    "dataset_name = 'CIFAR10'\n",
    "data_root = './data'\n",
    "\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "\n",
    "model = models.ResNet(models.resnet.Bottleneck, [3, 4, 6, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets\n",
    "\n",
    "dataset = getattr(datasets, dataset_name)(root=data_root, train=True, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset CIFAR10\n",
       "    Number of datapoints: 50000\n",
       "    Root location: ./data\n",
       "    Split: Train"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'airplane': 0,\n",
       " 'automobile': 1,\n",
       " 'bird': 2,\n",
       " 'cat': 3,\n",
       " 'deer': 4,\n",
       " 'dog': 5,\n",
       " 'frog': 6,\n",
       " 'horse': 7,\n",
       " 'ship': 8,\n",
       " 'truck': 9}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "target_classes = ['frog', 'horse']\n",
    "idx_to_class = {v: k for k, v in dataset.class_to_idx.items()}\n",
    "\n",
    "class_labels = pd.Series(dataset.targets).map(idx_to_class)\n",
    "interested_idx = np.where(class_labels.isin(target_classes))[0]\n",
    "subset_labels = class_labels.loc[interested_idx]\n",
    "\n",
    "label_map = {dataset.class_to_idx[cls]: ix for ix, cls in enumerate(target_classes)}\n",
    "target_transform = lambda x: label_map[x]\n",
    "\n",
    "del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_idx, val_idx = train_test_split(interested_idx, test_size=0.1, stratify=subset_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "import torchvision.transforms as tvt\n",
    "\n",
    "train_xform = tvt.Compose([\n",
    "    tvt.RandomAffine(degrees=20, shear=0.1),\n",
    "    tvt.RandomHorizontalFlip(p=0.5),\n",
    "    tvt.ToTensor()\n",
    "])\n",
    "val_xform = tvt.ToTensor()\n",
    "\n",
    "train_dataset = getattr(datasets, dataset_name)(root=data_root, train=True, transform=train_xform, target_transform=target_transform)\n",
    "val_dataset = getattr(datasets, dataset_name)(root=data_root, train=True, transform=val_xform, target_transform=target_transform)\n",
    "\n",
    "train_dl = DataLoader(train_dataset, batch_size=256, sampler=SubsetRandomSampler(train_idx), pin_memory=True, num_workers=2)\n",
    "val_dl = DataLoader(val_dataset, batch_size=256, sampler=SubsetRandomSampler(val_idx), pin_memory=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-1f8a688cae5d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "model.fc = nn.Linear(model.fc.in_features, len(target_classes))\n",
    "nn.init.kaiming_normal_(model.fc.weight)\n",
    "nn.init.constant_(model.fc.bias, 0.1)\n",
    "\n",
    "model.fc = nn.Sequential(nn.Dropout(0.5), model.fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import SGD\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "\n",
    "criterion = CrossEntropyLoss(reduction='mean').to(device)\n",
    "optimizer = SGD(params=model.parameters(), lr=0.01, weight_decay=5e-5)\n",
    "scheduler = ReduceLROnPlateau(optimizer, patience=10, cooldown=6, factor=0.1, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "train: {'loss': 1.6810294439395268}\n",
      "train:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.62      0.61      4500\n",
      "           1       0.61      0.60      0.60      4500\n",
      "\n",
      "    accuracy                           0.61      9000\n",
      "   macro avg       0.61      0.61      0.61      9000\n",
      "weighted avg       0.61      0.61      0.61      9000\n",
      "\n",
      "val: {'loss': 5.310507297515869}\n",
      "val:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.96      0.69       500\n",
      "           1       0.82      0.18      0.30       500\n",
      "\n",
      "    accuracy                           0.57      1000\n",
      "   macro avg       0.68      0.57      0.49      1000\n",
      "weighted avg       0.68      0.57      0.49      1000\n",
      "\n",
      "epoch: 1\n",
      "train: {'loss': 0.9385262570447392}\n",
      "train:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.70      0.69      4500\n",
      "           1       0.69      0.67      0.68      4500\n",
      "\n",
      "    accuracy                           0.68      9000\n",
      "   macro avg       0.68      0.68      0.68      9000\n",
      "weighted avg       0.68      0.68      0.68      9000\n",
      "\n",
      "val: {'loss': 0.6053154766559601}\n",
      "val:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.70      0.75       500\n",
      "           1       0.74      0.83      0.78       500\n",
      "\n",
      "    accuracy                           0.77      1000\n",
      "   macro avg       0.77      0.76      0.76      1000\n",
      "weighted avg       0.77      0.77      0.76      1000\n",
      "\n",
      "epoch: 2\n",
      "train: {'loss': 0.7979818102386262}\n",
      "train:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.73      0.73      4500\n",
      "           1       0.73      0.73      0.73      4500\n",
      "\n",
      "    accuracy                           0.73      9000\n",
      "   macro avg       0.73      0.73      0.73      9000\n",
      "weighted avg       0.73      0.73      0.73      9000\n",
      "\n",
      "val: {'loss': 1.86813685297966}\n",
      "val:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.24      0.39       500\n",
      "           1       0.57      0.99      0.72       500\n",
      "\n",
      "    accuracy                           0.61      1000\n",
      "   macro avg       0.76      0.61      0.55      1000\n",
      "weighted avg       0.76      0.61      0.55      1000\n",
      "\n",
      "epoch: 3\n",
      "train: {'loss': 0.654151347776254}\n",
      "train:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.76      0.77      4500\n",
      "           1       0.77      0.77      0.77      4500\n",
      "\n",
      "    accuracy                           0.77      9000\n",
      "   macro avg       0.77      0.77      0.77      9000\n",
      "weighted avg       0.77      0.77      0.77      9000\n",
      "\n",
      "val: {'loss': 0.6262236833572388}\n",
      "val:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.54      0.67       500\n",
      "           1       0.67      0.94      0.78       500\n",
      "\n",
      "    accuracy                           0.74      1000\n",
      "   macro avg       0.78      0.74      0.73      1000\n",
      "weighted avg       0.78      0.74      0.73      1000\n",
      "\n",
      "epoch: 4\n",
      "train: {'loss': 0.5616279807355669}\n",
      "train:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.79      4500\n",
      "           1       0.79      0.80      0.79      4500\n",
      "\n",
      "    accuracy                           0.79      9000\n",
      "   macro avg       0.79      0.79      0.79      9000\n",
      "weighted avg       0.79      0.79      0.79      9000\n",
      "\n",
      "val: {'loss': 0.42106059193611145}\n",
      "val:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.85      0.82       500\n",
      "           1       0.84      0.77      0.81       500\n",
      "\n",
      "    accuracy                           0.81      1000\n",
      "   macro avg       0.82      0.81      0.81      1000\n",
      "weighted avg       0.82      0.81      0.81      1000\n",
      "\n",
      "epoch: 5\n",
      "train: {'loss': 0.5109980834854974}\n",
      "train:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      4500\n",
      "           1       0.81      0.80      0.81      4500\n",
      "\n",
      "    accuracy                           0.81      9000\n",
      "   macro avg       0.81      0.81      0.81      9000\n",
      "weighted avg       0.81      0.81      0.81      9000\n",
      "\n",
      "val: {'loss': 0.6923560872673988}\n",
      "val:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.63      0.74       500\n",
      "           1       0.72      0.93      0.81       500\n",
      "\n",
      "    accuracy                           0.78      1000\n",
      "   macro avg       0.81      0.78      0.78      1000\n",
      "weighted avg       0.81      0.78      0.78      1000\n",
      "\n",
      "epoch: 6\n",
      "train: {'loss': 0.4910839522878329}\n",
      "train:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82      4500\n",
      "           1       0.83      0.82      0.82      4500\n",
      "\n",
      "    accuracy                           0.82      9000\n",
      "   macro avg       0.82      0.82      0.82      9000\n",
      "weighted avg       0.82      0.82      0.82      9000\n",
      "\n",
      "val: {'loss': 0.4014740362763405}\n",
      "val:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82       500\n",
      "           1       0.82      0.81      0.81       500\n",
      "\n",
      "    accuracy                           0.82      1000\n",
      "   macro avg       0.82      0.82      0.82      1000\n",
      "weighted avg       0.82      0.82      0.82      1000\n",
      "\n",
      "epoch: 7\n",
      "train: {'loss': 0.435063011944294}\n",
      "train:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.84      0.84      4500\n",
      "           1       0.84      0.83      0.84      4500\n",
      "\n",
      "    accuracy                           0.84      9000\n",
      "   macro avg       0.84      0.84      0.84      9000\n",
      "weighted avg       0.84      0.84      0.84      9000\n",
      "\n",
      "val: {'loss': 1.601631075143814}\n",
      "val:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.94      0.80       500\n",
      "           1       0.91      0.60      0.72       500\n",
      "\n",
      "    accuracy                           0.77      1000\n",
      "   macro avg       0.80      0.77      0.76      1000\n",
      "weighted avg       0.80      0.77      0.76      1000\n",
      "\n",
      "epoch: 8\n",
      "train: {'loss': 0.4598151478502486}\n",
      "train:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.85      0.84      4500\n",
      "           1       0.85      0.84      0.84      4500\n",
      "\n",
      "    accuracy                           0.84      9000\n",
      "   macro avg       0.84      0.84      0.84      9000\n",
      "weighted avg       0.84      0.84      0.84      9000\n",
      "\n",
      "val: {'loss': 0.39860621839761734}\n",
      "val:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.88      0.85       500\n",
      "           1       0.87      0.81      0.84       500\n",
      "\n",
      "    accuracy                           0.84      1000\n",
      "   macro avg       0.85      0.84      0.84      1000\n",
      "weighted avg       0.85      0.84      0.84      1000\n",
      "\n",
      "epoch: 9\n",
      "train: {'loss': 0.4577149252096812}\n",
      "train:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.85      0.84      4500\n",
      "           1       0.85      0.83      0.84      4500\n",
      "\n",
      "    accuracy                           0.84      9000\n",
      "   macro avg       0.84      0.84      0.84      9000\n",
      "weighted avg       0.84      0.84      0.84      9000\n",
      "\n",
      "val: {'loss': 0.5440566316246986}\n",
      "val:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.86      0.84       500\n",
      "           1       0.85      0.81      0.83       500\n",
      "\n",
      "    accuracy                           0.83      1000\n",
      "   macro avg       0.84      0.83      0.83      1000\n",
      "weighted avg       0.84      0.83      0.83      1000\n",
      "\n",
      "epoch: 10\n",
      "train: {'loss': 0.382357700003518}\n",
      "train:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.86      0.85      4500\n",
      "           1       0.86      0.85      0.85      4500\n",
      "\n",
      "    accuracy                           0.85      9000\n",
      "   macro avg       0.85      0.85      0.85      9000\n",
      "weighted avg       0.85      0.85      0.85      9000\n",
      "\n",
      "val: {'loss': 0.41236352175474167}\n",
      "val:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.87      0.85       500\n",
      "           1       0.86      0.83      0.85       500\n",
      "\n",
      "    accuracy                           0.85      1000\n",
      "   macro avg       0.85      0.85      0.85      1000\n",
      "weighted avg       0.85      0.85      0.85      1000\n",
      "\n",
      "epoch: 11\n",
      "train: {'loss': 0.35245289074050057}\n",
      "train:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.87      0.86      4500\n",
      "           1       0.87      0.86      0.86      4500\n",
      "\n",
      "    accuracy                           0.86      9000\n",
      "   macro avg       0.86      0.86      0.86      9000\n",
      "weighted avg       0.86      0.86      0.86      9000\n",
      "\n",
      "val: {'loss': 0.4444373771548271}\n",
      "val:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.89      0.86       500\n",
      "           1       0.88      0.82      0.85       500\n",
      "\n",
      "    accuracy                           0.85      1000\n",
      "   macro avg       0.86      0.85      0.85      1000\n",
      "weighted avg       0.86      0.85      0.85      1000\n",
      "\n",
      "epoch: 12\n",
      "train: {'loss': 0.37892797589302063}\n",
      "train:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.87      0.86      4500\n",
      "           1       0.87      0.85      0.86      4500\n",
      "\n",
      "    accuracy                           0.86      9000\n",
      "   macro avg       0.86      0.86      0.86      9000\n",
      "weighted avg       0.86      0.86      0.86      9000\n",
      "\n",
      "val: {'loss': 0.34547291696071625}\n",
      "val:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.89      0.87       500\n",
      "           1       0.88      0.84      0.86       500\n",
      "\n",
      "    accuracy                           0.86      1000\n",
      "   macro avg       0.86      0.86      0.86      1000\n",
      "weighted avg       0.86      0.86      0.86      1000\n",
      "\n",
      "epoch: 13\n",
      "train: {'loss': 0.36064833195673096}\n",
      "train:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.88      0.87      4500\n",
      "           1       0.88      0.86      0.87      4500\n",
      "\n",
      "    accuracy                           0.87      9000\n",
      "   macro avg       0.87      0.87      0.87      9000\n",
      "weighted avg       0.87      0.87      0.87      9000\n",
      "\n",
      "val: {'loss': 1.9436665773391724}\n",
      "val:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.94      0.84       500\n",
      "           1       0.92      0.69      0.79       500\n",
      "\n",
      "    accuracy                           0.82      1000\n",
      "   macro avg       0.84      0.82      0.81      1000\n",
      "weighted avg       0.84      0.82      0.81      1000\n",
      "\n",
      "epoch: 14\n",
      "train: {'loss': 0.3547854589091407}\n",
      "train:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.88      0.87      4500\n",
      "           1       0.88      0.87      0.87      4500\n",
      "\n",
      "    accuracy                           0.87      9000\n",
      "   macro avg       0.87      0.87      0.87      9000\n",
      "weighted avg       0.87      0.87      0.87      9000\n",
      "\n",
      "val: {'loss': 0.4131731390953064}\n",
      "val:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.93      0.87       500\n",
      "           1       0.92      0.78      0.84       500\n",
      "\n",
      "    accuracy                           0.85      1000\n",
      "   macro avg       0.86      0.85      0.85      1000\n",
      "weighted avg       0.86      0.85      0.85      1000\n",
      "\n",
      "epoch: 15\n",
      "train: {'loss': 0.3297947566542361}\n",
      "train:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.89      0.88      4500\n",
      "           1       0.89      0.87      0.88      4500\n",
      "\n",
      "    accuracy                           0.88      9000\n",
      "   macro avg       0.88      0.88      0.88      9000\n",
      "weighted avg       0.88      0.88      0.88      9000\n",
      "\n",
      "val: {'loss': 0.3234979137778282}\n",
      "val:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.89      0.88       500\n",
      "           1       0.89      0.86      0.87       500\n",
      "\n",
      "    accuracy                           0.88      1000\n",
      "   macro avg       0.88      0.88      0.88      1000\n",
      "weighted avg       0.88      0.88      0.88      1000\n",
      "\n",
      "epoch: 16\n",
      "train: {'loss': 0.29710491912232506}\n",
      "train:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.89      4500\n",
      "           1       0.89      0.88      0.88      4500\n",
      "\n",
      "    accuracy                           0.88      9000\n",
      "   macro avg       0.88      0.88      0.88      9000\n",
      "weighted avg       0.88      0.88      0.88      9000\n",
      "\n",
      "val: {'loss': 0.4101010635495186}\n",
      "val:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.91      0.87       500\n",
      "           1       0.90      0.82      0.86       500\n",
      "\n",
      "    accuracy                           0.86      1000\n",
      "   macro avg       0.87      0.86      0.86      1000\n",
      "weighted avg       0.87      0.86      0.86      1000\n",
      "\n",
      "epoch: 17\n",
      "train: {'loss': 0.29445267137553954}\n",
      "train:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.90      0.89      4500\n",
      "           1       0.90      0.88      0.89      4500\n",
      "\n",
      "    accuracy                           0.89      9000\n",
      "   macro avg       0.89      0.89      0.89      9000\n",
      "weighted avg       0.89      0.89      0.89      9000\n",
      "\n",
      "val: {'loss': 0.3215419203042984}\n",
      "val:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.90      0.87       500\n",
      "           1       0.90      0.84      0.87       500\n",
      "\n",
      "    accuracy                           0.87      1000\n",
      "   macro avg       0.87      0.87      0.87      1000\n",
      "weighted avg       0.87      0.87      0.87      1000\n",
      "\n",
      "epoch: 18\n",
      "train: {'loss': 0.2867084774706099}\n",
      "train:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.90      0.89      4500\n",
      "           1       0.90      0.89      0.89      4500\n",
      "\n",
      "    accuracy                           0.89      9000\n",
      "   macro avg       0.89      0.89      0.89      9000\n",
      "weighted avg       0.89      0.89      0.89      9000\n",
      "\n",
      "val: {'loss': 0.37288767099380493}\n",
      "val:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.79      0.85       500\n",
      "           1       0.82      0.92      0.86       500\n",
      "\n",
      "    accuracy                           0.85      1000\n",
      "   macro avg       0.86      0.85      0.85      1000\n",
      "weighted avg       0.86      0.85      0.85      1000\n",
      "\n",
      "epoch: 19\n",
      "train: {'loss': 0.29141025783287156}\n",
      "train:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.90      0.90      4500\n",
      "           1       0.90      0.90      0.90      4500\n",
      "\n",
      "    accuracy                           0.90      9000\n",
      "   macro avg       0.90      0.90      0.90      9000\n",
      "weighted avg       0.90      0.90      0.90      9000\n",
      "\n",
      "val: {'loss': 2.1168010532855988}\n",
      "val:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.95      0.83       500\n",
      "           1       0.93      0.65      0.77       500\n",
      "\n",
      "    accuracy                           0.80      1000\n",
      "   macro avg       0.83      0.80      0.80      1000\n",
      "weighted avg       0.83      0.80      0.80      1000\n",
      "\n",
      "epoch: 20\n",
      "train: {'loss': 0.2862987046440442}\n",
      "train:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.90      0.90      4500\n",
      "           1       0.90      0.89      0.89      4500\n",
      "\n",
      "    accuracy                           0.90      9000\n",
      "   macro avg       0.90      0.90      0.90      9000\n",
      "weighted avg       0.90      0.90      0.90      9000\n",
      "\n",
      "val: {'loss': 0.31044667214155197}\n",
      "val:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.92      0.88       500\n",
      "           1       0.91      0.83      0.87       500\n",
      "\n",
      "    accuracy                           0.88      1000\n",
      "   macro avg       0.88      0.88      0.88      1000\n",
      "weighted avg       0.88      0.88      0.88      1000\n",
      "\n",
      "epoch: 21\n",
      "train: {'loss': 0.2538018102447192}\n",
      "train:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.91      0.91      4500\n",
      "           1       0.91      0.90      0.90      4500\n",
      "\n",
      "    accuracy                           0.90      9000\n",
      "   macro avg       0.90      0.90      0.90      9000\n",
      "weighted avg       0.90      0.90      0.90      9000\n",
      "\n",
      "val: {'loss': 0.25682996213436127}\n",
      "val:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.89      0.89       500\n",
      "           1       0.89      0.89      0.89       500\n",
      "\n",
      "    accuracy                           0.89      1000\n",
      "   macro avg       0.89      0.89      0.89      1000\n",
      "weighted avg       0.89      0.89      0.89      1000\n",
      "\n",
      "epoch: 22\n",
      "train: {'loss': 0.2777746551566654}\n",
      "train:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.91      0.91      4500\n",
      "           1       0.91      0.90      0.91      4500\n",
      "\n",
      "    accuracy                           0.91      9000\n",
      "   macro avg       0.91      0.91      0.91      9000\n",
      "weighted avg       0.91      0.91      0.91      9000\n",
      "\n",
      "val: {'loss': 4.099980354309082}\n",
      "val:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.97      0.78       500\n",
      "           1       0.95      0.49      0.64       500\n",
      "\n",
      "    accuracy                           0.73      1000\n",
      "   macro avg       0.80      0.73      0.71      1000\n",
      "weighted avg       0.80      0.73      0.71      1000\n",
      "\n",
      "epoch: 23\n",
      "train: {'loss': 0.30397744642363655}\n",
      "train:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.91      0.91      4500\n",
      "           1       0.91      0.90      0.90      4500\n",
      "\n",
      "    accuracy                           0.90      9000\n",
      "   macro avg       0.90      0.90      0.90      9000\n",
      "weighted avg       0.90      0.90      0.90      9000\n",
      "\n",
      "val: {'loss': 0.31495917588472366}\n",
      "val:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.87      0.89       500\n",
      "           1       0.88      0.91      0.89       500\n",
      "\n",
      "    accuracy                           0.89      1000\n",
      "   macro avg       0.89      0.89      0.89      1000\n",
      "weighted avg       0.89      0.89      0.89      1000\n",
      "\n",
      "epoch: 24\n",
      "train: {'loss': 0.2254072448445691}\n",
      "train:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.92      0.91      4500\n",
      "           1       0.92      0.91      0.91      4500\n",
      "\n",
      "    accuracy                           0.91      9000\n",
      "   macro avg       0.91      0.91      0.91      9000\n",
      "weighted avg       0.91      0.91      0.91      9000\n",
      "\n",
      "val: {'loss': 0.27492376416921616}\n",
      "val:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.92      0.89       500\n",
      "           1       0.91      0.85      0.88       500\n",
      "\n",
      "    accuracy                           0.89      1000\n",
      "   macro avg       0.89      0.89      0.88      1000\n",
      "weighted avg       0.89      0.89      0.88      1000\n",
      "\n",
      "epoch: 25\n",
      "train: {'loss': 0.21790769199530283}\n",
      "train:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.92      0.92      4500\n",
      "           1       0.92      0.91      0.92      4500\n",
      "\n",
      "    accuracy                           0.92      9000\n",
      "   macro avg       0.92      0.92      0.92      9000\n",
      "weighted avg       0.92      0.92      0.92      9000\n",
      "\n",
      "val: {'loss': 0.38741081207990646}\n",
      "val:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.87      0.88       500\n",
      "           1       0.87      0.90      0.89       500\n",
      "\n",
      "    accuracy                           0.89      1000\n",
      "   macro avg       0.89      0.89      0.88      1000\n",
      "weighted avg       0.89      0.89      0.88      1000\n",
      "\n",
      "epoch: 26\n",
      "train: {'loss': 0.2015322902136379}\n",
      "train:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92      4500\n",
      "           1       0.92      0.91      0.92      4500\n",
      "\n",
      "    accuracy                           0.92      9000\n",
      "   macro avg       0.92      0.92      0.92      9000\n",
      "weighted avg       0.92      0.92      0.92      9000\n",
      "\n",
      "val: {'loss': 0.30905164778232574}\n",
      "val:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.90      0.89       500\n",
      "           1       0.90      0.87      0.88       500\n",
      "\n",
      "    accuracy                           0.89      1000\n",
      "   macro avg       0.89      0.89      0.88      1000\n",
      "weighted avg       0.89      0.89      0.88      1000\n",
      "\n",
      "epoch: 27\n",
      "train: {'loss': 0.21115783808959854}\n",
      "train:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92      4500\n",
      "           1       0.92      0.92      0.92      4500\n",
      "\n",
      "    accuracy                           0.92      9000\n",
      "   macro avg       0.92      0.92      0.92      9000\n",
      "weighted avg       0.92      0.92      0.92      9000\n",
      "\n",
      "val: {'loss': 0.23810923472046852}\n",
      "val:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.92      0.91       500\n",
      "           1       0.92      0.89      0.90       500\n",
      "\n",
      "    accuracy                           0.91      1000\n",
      "   macro avg       0.91      0.91      0.91      1000\n",
      "weighted avg       0.91      0.91      0.91      1000\n",
      "\n",
      "epoch: 28\n",
      "train: {'loss': 0.19033694763978323}\n",
      "train:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.93      0.93      4500\n",
      "           1       0.93      0.92      0.92      4500\n",
      "\n",
      "    accuracy                           0.92      9000\n",
      "   macro avg       0.92      0.92      0.92      9000\n",
      "weighted avg       0.92      0.92      0.92      9000\n",
      "\n",
      "val: {'loss': 0.2913004532456398}\n",
      "val:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.92      0.90       500\n",
      "           1       0.92      0.88      0.90       500\n",
      "\n",
      "    accuracy                           0.90      1000\n",
      "   macro avg       0.90      0.90      0.90      1000\n",
      "weighted avg       0.90      0.90      0.90      1000\n",
      "\n",
      "epoch: 29\n",
      "train: {'loss': 0.18907852719227472}\n",
      "train:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93      4500\n",
      "           1       0.93      0.92      0.93      4500\n",
      "\n",
      "    accuracy                           0.93      9000\n",
      "   macro avg       0.93      0.93      0.93      9000\n",
      "weighted avg       0.93      0.93      0.93      9000\n",
      "\n",
      "val: {'loss': 0.26770125329494476}\n",
      "val:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.90      0.90       500\n",
      "           1       0.90      0.90      0.90       500\n",
      "\n",
      "    accuracy                           0.90      1000\n",
      "   macro avg       0.90      0.90      0.90      1000\n",
      "weighted avg       0.90      0.90      0.90      1000\n",
      "\n",
      "epoch: 30\n",
      "train: {'loss': 0.1914261124200291}\n",
      "train:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.93      0.93      4500\n",
      "           1       0.93      0.92      0.93      4500\n",
      "\n",
      "    accuracy                           0.93      9000\n",
      "   macro avg       0.93      0.93      0.93      9000\n",
      "weighted avg       0.93      0.93      0.93      9000\n",
      "\n",
      "val: {'loss': 0.23722118511795998}\n",
      "val:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.91      0.90       500\n",
      "           1       0.91      0.90      0.90       500\n",
      "\n",
      "    accuracy                           0.90      1000\n",
      "   macro avg       0.90      0.90      0.90      1000\n",
      "weighted avg       0.90      0.90      0.90      1000\n",
      "\n",
      "epoch: 31\n",
      "train: {'loss': 0.17012840447326502}\n",
      "train:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93      4500\n",
      "           1       0.93      0.94      0.93      4500\n",
      "\n",
      "    accuracy                           0.93      9000\n",
      "   macro avg       0.93      0.93      0.93      9000\n",
      "weighted avg       0.93      0.93      0.93      9000\n",
      "\n",
      "val: {'loss': 0.2337128221988678}\n",
      "val:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.90      0.91       500\n",
      "           1       0.90      0.92      0.91       500\n",
      "\n",
      "    accuracy                           0.91      1000\n",
      "   macro avg       0.91      0.91      0.91      1000\n",
      "weighted avg       0.91      0.91      0.91      1000\n",
      "\n",
      "epoch: 32\n",
      "train: {'loss': 0.18593564050065148}\n",
      "train:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93      4500\n",
      "           1       0.93      0.93      0.93      4500\n",
      "\n",
      "    accuracy                           0.93      9000\n",
      "   macro avg       0.93      0.93      0.93      9000\n",
      "weighted avg       0.93      0.93      0.93      9000\n",
      "\n",
      "val: {'loss': 0.2904108241200447}\n",
      "val:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.84      0.88       500\n",
      "           1       0.86      0.93      0.89       500\n",
      "\n",
      "    accuracy                           0.89      1000\n",
      "   macro avg       0.89      0.89      0.89      1000\n",
      "weighted avg       0.89      0.89      0.89      1000\n",
      "\n",
      "epoch: 33\n",
      "train: {'loss': 0.1817647253887521}\n",
      "train:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93      4500\n",
      "           1       0.93      0.94      0.93      4500\n",
      "\n",
      "    accuracy                           0.93      9000\n",
      "   macro avg       0.93      0.93      0.93      9000\n",
      "weighted avg       0.93      0.93      0.93      9000\n",
      "\n",
      "val: {'loss': 0.2647398114204407}\n",
      "val:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.88      0.89       500\n",
      "           1       0.88      0.90      0.89       500\n",
      "\n",
      "    accuracy                           0.89      1000\n",
      "   macro avg       0.89      0.89      0.89      1000\n",
      "weighted avg       0.89      0.89      0.89      1000\n",
      "\n",
      "epoch: 34\n",
      "train: {'loss': 0.16876273105541864}\n",
      "train:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.94      4500\n",
      "           1       0.94      0.93      0.93      4500\n",
      "\n",
      "    accuracy                           0.93      9000\n",
      "   macro avg       0.93      0.93      0.93      9000\n",
      "weighted avg       0.93      0.93      0.93      9000\n",
      "\n",
      "val: {'loss': 0.27729126811027527}\n",
      "val:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.89      0.90       500\n",
      "           1       0.89      0.92      0.91       500\n",
      "\n",
      "    accuracy                           0.91      1000\n",
      "   macro avg       0.91      0.91      0.91      1000\n",
      "weighted avg       0.91      0.91      0.91      1000\n",
      "\n",
      "epoch: 35\n",
      "train: {'loss': 0.15323503812154135}\n",
      "train:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.94      4500\n",
      "           1       0.94      0.94      0.94      4500\n",
      "\n",
      "    accuracy                           0.94      9000\n",
      "   macro avg       0.94      0.94      0.94      9000\n",
      "weighted avg       0.94      0.94      0.94      9000\n",
      "\n",
      "val: {'loss': 0.28823044523596764}\n",
      "val:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.85      0.89       500\n",
      "           1       0.86      0.94      0.90       500\n",
      "\n",
      "    accuracy                           0.90      1000\n",
      "   macro avg       0.90      0.90      0.90      1000\n",
      "weighted avg       0.90      0.90      0.90      1000\n",
      "\n",
      "epoch: 36\n",
      "train: {'loss': 0.1562975240457389}\n",
      "train:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94      4500\n",
      "           1       0.94      0.94      0.94      4500\n",
      "\n",
      "    accuracy                           0.94      9000\n",
      "   macro avg       0.94      0.94      0.94      9000\n",
      "weighted avg       0.94      0.94      0.94      9000\n",
      "\n",
      "val: {'loss': 0.24721873551607132}\n",
      "val:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.91      0.91       500\n",
      "           1       0.91      0.92      0.91       500\n",
      "\n",
      "    accuracy                           0.91      1000\n",
      "   macro avg       0.91      0.91      0.91      1000\n",
      "weighted avg       0.91      0.91      0.91      1000\n",
      "\n",
      "epoch: 37\n",
      "train: {'loss': 0.1593066675381528}\n",
      "train:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94      4500\n",
      "           1       0.94      0.94      0.94      4500\n",
      "\n",
      "    accuracy                           0.94      9000\n",
      "   macro avg       0.94      0.94      0.94      9000\n",
      "weighted avg       0.94      0.94      0.94      9000\n",
      "\n",
      "val: {'loss': 0.2961585111916065}\n",
      "val:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.93      0.89       500\n",
      "           1       0.92      0.85      0.89       500\n",
      "\n",
      "    accuracy                           0.89      1000\n",
      "   macro avg       0.89      0.89      0.89      1000\n",
      "weighted avg       0.89      0.89      0.89      1000\n",
      "\n",
      "epoch: 38\n",
      "train: {'loss': 0.15876537064711252}\n",
      "train:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94      4500\n",
      "           1       0.95      0.93      0.94      4500\n",
      "\n",
      "    accuracy                           0.94      9000\n",
      "   macro avg       0.94      0.94      0.94      9000\n",
      "weighted avg       0.94      0.94      0.94      9000\n",
      "\n",
      "val: {'loss': 0.24557241424918175}\n",
      "val:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.90      0.91       500\n",
      "           1       0.90      0.92      0.91       500\n",
      "\n",
      "    accuracy                           0.91      1000\n",
      "   macro avg       0.91      0.91      0.91      1000\n",
      "weighted avg       0.91      0.91      0.91      1000\n",
      "\n",
      "epoch: 39\n",
      "train: {'loss': 0.15140151605010033}\n",
      "train:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.94      4500\n",
      "           1       0.95      0.94      0.94      4500\n",
      "\n",
      "    accuracy                           0.94      9000\n",
      "   macro avg       0.94      0.94      0.94      9000\n",
      "weighted avg       0.94      0.94      0.94      9000\n",
      "\n",
      "val: {'loss': 1.7276303470134735}\n",
      "val:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.89      0.83       500\n",
      "           1       0.87      0.74      0.80       500\n",
      "\n",
      "    accuracy                           0.81      1000\n",
      "   macro avg       0.82      0.81      0.81      1000\n",
      "weighted avg       0.82      0.81      0.81      1000\n",
      "\n",
      "epoch: 40\n",
      "train: {'loss': 0.1694925824801127}\n",
      "train:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94      4500\n",
      "           1       0.94      0.94      0.94      4500\n",
      "\n",
      "    accuracy                           0.94      9000\n",
      "   macro avg       0.94      0.94      0.94      9000\n",
      "weighted avg       0.94      0.94      0.94      9000\n",
      "\n",
      "val: {'loss': 1.561955213546753}\n",
      "val:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.90      0.85       500\n",
      "           1       0.88      0.78      0.83       500\n",
      "\n",
      "    accuracy                           0.84      1000\n",
      "   macro avg       0.84      0.84      0.84      1000\n",
      "weighted avg       0.84      0.84      0.84      1000\n",
      "\n",
      "epoch: 41\n",
      "train: {'loss': 0.15919519981576336}\n",
      "train:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95      4500\n",
      "           1       0.95      0.95      0.95      4500\n",
      "\n",
      "    accuracy                           0.95      9000\n",
      "   macro avg       0.95      0.95      0.95      9000\n",
      "weighted avg       0.95      0.95      0.95      9000\n",
      "\n",
      "val: {'loss': 0.9008166193962097}\n",
      "val:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.94      0.86       500\n",
      "           1       0.93      0.77      0.84       500\n",
      "\n",
      "    accuracy                           0.85      1000\n",
      "   macro avg       0.86      0.85      0.85      1000\n",
      "weighted avg       0.86      0.85      0.85      1000\n",
      "\n",
      "epoch: 42\n",
      "train: {'loss': 0.14075996892319786}\n",
      "train:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95      4500\n",
      "           1       0.95      0.95      0.95      4500\n",
      "\n",
      "    accuracy                           0.95      9000\n",
      "   macro avg       0.95      0.95      0.95      9000\n",
      "weighted avg       0.95      0.95      0.95      9000\n",
      "\n",
      "val: {'loss': 0.3163648247718811}\n",
      "val:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.89      0.89       500\n",
      "           1       0.89      0.89      0.89       500\n",
      "\n",
      "    accuracy                           0.89      1000\n",
      "   macro avg       0.89      0.89      0.89      1000\n",
      "weighted avg       0.89      0.89      0.89      1000\n",
      "\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-03.\n",
      "epoch: 43\n",
      "train: {'loss': 0.1378131705439753}\n",
      "train:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.95      4500\n",
      "           1       0.95      0.94      0.95      4500\n",
      "\n",
      "    accuracy                           0.95      9000\n",
      "   macro avg       0.95      0.95      0.95      9000\n",
      "weighted avg       0.95      0.95      0.95      9000\n",
      "\n",
      "val: {'loss': 0.26986831426620483}\n",
      "val:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.91      0.90       500\n",
      "           1       0.91      0.89      0.90       500\n",
      "\n",
      "    accuracy                           0.90      1000\n",
      "   macro avg       0.90      0.90      0.90      1000\n",
      "weighted avg       0.90      0.90      0.90      1000\n",
      "\n",
      "epoch: 44\n",
      "train: {'loss': 0.13100829989545876}\n",
      "train:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95      4500\n",
      "           1       0.95      0.95      0.95      4500\n",
      "\n",
      "    accuracy                           0.95      9000\n",
      "   macro avg       0.95      0.95      0.95      9000\n",
      "weighted avg       0.95      0.95      0.95      9000\n",
      "\n",
      "val: {'loss': 0.26113706082105637}\n",
      "val:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.90      0.90       500\n",
      "           1       0.90      0.90      0.90       500\n",
      "\n",
      "    accuracy                           0.90      1000\n",
      "   macro avg       0.90      0.90      0.90      1000\n",
      "weighted avg       0.90      0.90      0.90      1000\n",
      "\n",
      "epoch: 45\n",
      "train: {'loss': 0.11372542629639308}\n",
      "train:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.96      4500\n",
      "           1       0.96      0.95      0.96      4500\n",
      "\n",
      "    accuracy                           0.96      9000\n",
      "   macro avg       0.96      0.96      0.96      9000\n",
      "weighted avg       0.96      0.96      0.96      9000\n",
      "\n",
      "val: {'loss': 0.27055490761995316}\n",
      "val:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.89      0.90       500\n",
      "           1       0.89      0.90      0.90       500\n",
      "\n",
      "    accuracy                           0.90      1000\n",
      "   macro avg       0.90      0.90      0.90      1000\n",
      "weighted avg       0.90      0.90      0.90      1000\n",
      "\n",
      "epoch: 46\n",
      "train: {'loss': 0.11139659914705488}\n",
      "train:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.96      4500\n",
      "           1       0.96      0.95      0.96      4500\n",
      "\n",
      "    accuracy                           0.96      9000\n",
      "   macro avg       0.96      0.96      0.96      9000\n",
      "weighted avg       0.96      0.96      0.96      9000\n",
      "\n",
      "val: {'loss': 0.2655932568013668}\n",
      "val:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.90      0.91       500\n",
      "           1       0.90      0.91      0.91       500\n",
      "\n",
      "    accuracy                           0.91      1000\n",
      "   macro avg       0.91      0.91      0.91      1000\n",
      "weighted avg       0.91      0.91      0.91      1000\n",
      "\n",
      "epoch: 47\n",
      "train: {'loss': 0.11376242111954424}\n",
      "train:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      4500\n",
      "           1       0.96      0.96      0.96      4500\n",
      "\n",
      "    accuracy                           0.96      9000\n",
      "   macro avg       0.96      0.96      0.96      9000\n",
      "weighted avg       0.96      0.96      0.96      9000\n",
      "\n",
      "val: {'loss': 0.2501985430717468}\n",
      "val:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.92      0.91       500\n",
      "           1       0.92      0.90      0.91       500\n",
      "\n",
      "    accuracy                           0.91      1000\n",
      "   macro avg       0.91      0.91      0.91      1000\n",
      "weighted avg       0.91      0.91      0.91      1000\n",
      "\n",
      "epoch: 48\n",
      "train: {'loss': 0.10665329235295455}\n",
      "train:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      4500\n",
      "           1       0.96      0.96      0.96      4500\n",
      "\n",
      "    accuracy                           0.96      9000\n",
      "   macro avg       0.96      0.96      0.96      9000\n",
      "weighted avg       0.96      0.96      0.96      9000\n",
      "\n",
      "val: {'loss': 0.2638971768319607}\n",
      "val:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.90      0.90       500\n",
      "           1       0.90      0.90      0.90       500\n",
      "\n",
      "    accuracy                           0.90      1000\n",
      "   macro avg       0.90      0.90      0.90      1000\n",
      "weighted avg       0.90      0.90      0.90      1000\n",
      "\n",
      "epoch: 49\n",
      "train: {'loss': 0.11434438741869396}\n",
      "train:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      4500\n",
      "           1       0.96      0.96      0.96      4500\n",
      "\n",
      "    accuracy                           0.96      9000\n",
      "   macro avg       0.96      0.96      0.96      9000\n",
      "weighted avg       0.96      0.96      0.96      9000\n",
      "\n",
      "val: {'loss': 0.2566252760589123}\n",
      "val:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.90      0.91       500\n",
      "           1       0.90      0.91      0.91       500\n",
      "\n",
      "    accuracy                           0.91      1000\n",
      "   macro avg       0.91      0.91      0.91      1000\n",
      "weighted avg       0.91      0.91      0.91      1000\n",
      "\n",
      "epoch: 50\n",
      "train: {'loss': 0.10747551711069213}\n",
      "train:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      4500\n",
      "           1       0.96      0.96      0.96      4500\n",
      "\n",
      "    accuracy                           0.96      9000\n",
      "   macro avg       0.96      0.96      0.96      9000\n",
      "weighted avg       0.96      0.96      0.96      9000\n",
      "\n",
      "val: {'loss': 0.265955813229084}\n",
      "val:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91       500\n",
      "           1       0.91      0.91      0.91       500\n",
      "\n",
      "    accuracy                           0.91      1000\n",
      "   macro avg       0.91      0.91      0.91      1000\n",
      "weighted avg       0.91      0.91      0.91      1000\n",
      "\n",
      "epoch: 51\n",
      "train: {'loss': 0.118414672712485}\n",
      "train:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      4500\n",
      "           1       0.96      0.96      0.96      4500\n",
      "\n",
      "    accuracy                           0.96      9000\n",
      "   macro avg       0.96      0.96      0.96      9000\n",
      "weighted avg       0.96      0.96      0.96      9000\n",
      "\n",
      "val: {'loss': 0.2737793140113354}\n",
      "val:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.89      0.90       500\n",
      "           1       0.90      0.91      0.90       500\n",
      "\n",
      "    accuracy                           0.90      1000\n",
      "   macro avg       0.90      0.90      0.90      1000\n",
      "weighted avg       0.90      0.90      0.90      1000\n",
      "\n",
      "epoch: 52\n",
      "train: {'loss': 0.1130852403326167}\n",
      "train:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      4500\n",
      "           1       0.96      0.96      0.96      4500\n",
      "\n",
      "    accuracy                           0.96      9000\n",
      "   macro avg       0.96      0.96      0.96      9000\n",
      "weighted avg       0.96      0.96      0.96      9000\n",
      "\n",
      "val: {'loss': 0.27220068499445915}\n",
      "val:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.90      0.90       500\n",
      "           1       0.90      0.91      0.91       500\n",
      "\n",
      "    accuracy                           0.91      1000\n",
      "   macro avg       0.91      0.91      0.90      1000\n",
      "weighted avg       0.91      0.91      0.90      1000\n",
      "\n",
      "epoch: 53\n",
      "train: {'loss': 0.11282944741348426}\n",
      "train:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      4500\n",
      "           1       0.96      0.96      0.96      4500\n",
      "\n",
      "    accuracy                           0.96      9000\n",
      "   macro avg       0.96      0.96      0.96      9000\n",
      "weighted avg       0.96      0.96      0.96      9000\n",
      "\n",
      "val: {'loss': 0.2574036903679371}\n",
      "val:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.89      0.90       500\n",
      "           1       0.90      0.92      0.91       500\n",
      "\n",
      "    accuracy                           0.91      1000\n",
      "   macro avg       0.91      0.91      0.90      1000\n",
      "weighted avg       0.91      0.91      0.90      1000\n",
      "\n",
      "epoch: 54\n",
      "train: {'loss': 0.11061632126155826}\n",
      "train:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      4500\n",
      "           1       0.96      0.96      0.96      4500\n",
      "\n",
      "    accuracy                           0.96      9000\n",
      "   macro avg       0.96      0.96      0.96      9000\n",
      "weighted avg       0.96      0.96      0.96      9000\n",
      "\n",
      "val: {'loss': 0.25305482000112534}\n",
      "val:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.92      0.91       500\n",
      "           1       0.92      0.91      0.91       500\n",
      "\n",
      "    accuracy                           0.91      1000\n",
      "   macro avg       0.91      0.91      0.91      1000\n",
      "weighted avg       0.91      0.91      0.91      1000\n",
      "\n",
      "epoch: 55\n",
      "train: {'loss': 0.1134102452132437}\n",
      "train:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      4500\n",
      "           1       0.96      0.96      0.96      4500\n",
      "\n",
      "    accuracy                           0.96      9000\n",
      "   macro avg       0.96      0.96      0.96      9000\n",
      "weighted avg       0.96      0.96      0.96      9000\n",
      "\n",
      "val: {'loss': 0.2563194967806339}\n",
      "val:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.90      0.90       500\n",
      "           1       0.90      0.91      0.90       500\n",
      "\n",
      "    accuracy                           0.90      1000\n",
      "   macro avg       0.90      0.90      0.90      1000\n",
      "weighted avg       0.90      0.90      0.90      1000\n",
      "\n",
      "epoch: 56\n",
      "train: {'loss': 0.10995537746283743}\n",
      "train:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      4500\n",
      "           1       0.96      0.96      0.96      4500\n",
      "\n",
      "    accuracy                           0.96      9000\n",
      "   macro avg       0.96      0.96      0.96      9000\n",
      "weighted avg       0.96      0.96      0.96      9000\n",
      "\n",
      "val: {'loss': 0.2543124333024025}\n",
      "val:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91       500\n",
      "           1       0.91      0.91      0.91       500\n",
      "\n",
      "    accuracy                           0.91      1000\n",
      "   macro avg       0.91      0.91      0.91      1000\n",
      "weighted avg       0.91      0.91      0.91      1000\n",
      "\n",
      "epoch: 57\n",
      "train: {'loss': 0.10557522893779808}\n",
      "train:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96      4500\n",
      "           1       0.97      0.96      0.96      4500\n",
      "\n",
      "    accuracy                           0.96      9000\n",
      "   macro avg       0.96      0.96      0.96      9000\n",
      "weighted avg       0.96      0.96      0.96      9000\n",
      "\n",
      "val: {'loss': 0.2535136677324772}\n",
      "val:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.91      0.91       500\n",
      "           1       0.91      0.90      0.90       500\n",
      "\n",
      "    accuracy                           0.91      1000\n",
      "   macro avg       0.91      0.91      0.90      1000\n",
      "weighted avg       0.91      0.91      0.90      1000\n",
      "\n",
      "epoch: 58\n",
      "train: {'loss': 0.10601539558006658}\n",
      "train:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      4500\n",
      "           1       0.96      0.96      0.96      4500\n",
      "\n",
      "    accuracy                           0.96      9000\n",
      "   macro avg       0.96      0.96      0.96      9000\n",
      "weighted avg       0.96      0.96      0.96      9000\n",
      "\n",
      "val: {'loss': 0.2573021538555622}\n",
      "val:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91       500\n",
      "           1       0.91      0.91      0.91       500\n",
      "\n",
      "    accuracy                           0.91      1000\n",
      "   macro avg       0.91      0.91      0.91      1000\n",
      "weighted avg       0.91      0.91      0.91      1000\n",
      "\n",
      "epoch: 59\n",
      "train: {'loss': 0.10240181804531151}\n",
      "train:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      4500\n",
      "           1       0.96      0.96      0.96      4500\n",
      "\n",
      "    accuracy                           0.96      9000\n",
      "   macro avg       0.96      0.96      0.96      9000\n",
      "weighted avg       0.96      0.96      0.96      9000\n",
      "\n",
      "val: {'loss': 0.2504236213862896}\n",
      "val:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91       500\n",
      "           1       0.91      0.91      0.91       500\n",
      "\n",
      "    accuracy                           0.91      1000\n",
      "   macro avg       0.91      0.91      0.91      1000\n",
      "weighted avg       0.91      0.91      0.91      1000\n",
      "\n",
      "Epoch    59: reducing learning rate of group 0 to 1.0000e-04.\n",
      "epoch: 60\n",
      "train: {'loss': 0.10711863616274463}\n",
      "train:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.97      4500\n",
      "           1       0.96      0.97      0.97      4500\n",
      "\n",
      "    accuracy                           0.97      9000\n",
      "   macro avg       0.97      0.97      0.97      9000\n",
      "weighted avg       0.97      0.97      0.97      9000\n",
      "\n",
      "val: {'loss': 0.260789941996336}\n",
      "val:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.90      0.91       500\n",
      "           1       0.90      0.91      0.91       500\n",
      "\n",
      "    accuracy                           0.91      1000\n",
      "   macro avg       0.91      0.91      0.91      1000\n",
      "weighted avg       0.91      0.91      0.91      1000\n",
      "\n",
      "epoch: 61\n",
      "train: {'loss': 0.09658680618223217}\n",
      "train:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96      4500\n",
      "           1       0.97      0.96      0.96      4500\n",
      "\n",
      "    accuracy                           0.96      9000\n",
      "   macro avg       0.96      0.96      0.96      9000\n",
      "weighted avg       0.96      0.96      0.96      9000\n",
      "\n",
      "val: {'loss': 0.2549842298030853}\n",
      "val:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.90      0.90       500\n",
      "           1       0.90      0.90      0.90       500\n",
      "\n",
      "    accuracy                           0.90      1000\n",
      "   macro avg       0.90      0.90      0.90      1000\n",
      "weighted avg       0.90      0.90      0.90      1000\n",
      "\n",
      "epoch: 62\n",
      "train: {'loss': 0.10963342659589317}\n",
      "train:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      4500\n",
      "           1       0.96      0.96      0.96      4500\n",
      "\n",
      "    accuracy                           0.96      9000\n",
      "   macro avg       0.96      0.96      0.96      9000\n",
      "weighted avg       0.96      0.96      0.96      9000\n",
      "\n",
      "val: {'loss': 0.25266239792108536}\n",
      "val:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.90      0.91       500\n",
      "           1       0.90      0.91      0.91       500\n",
      "\n",
      "    accuracy                           0.91      1000\n",
      "   macro avg       0.91      0.91      0.91      1000\n",
      "weighted avg       0.91      0.91      0.91      1000\n",
      "\n",
      "epoch: 63\n",
      "train: {'loss': 0.09383721416816115}\n",
      "train:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      4500\n",
      "           1       0.96      0.96      0.96      4500\n",
      "\n",
      "    accuracy                           0.96      9000\n",
      "   macro avg       0.96      0.96      0.96      9000\n",
      "weighted avg       0.96      0.96      0.96      9000\n",
      "\n",
      "val: {'loss': 0.25619957596063614}\n",
      "val:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91       500\n",
      "           1       0.91      0.91      0.91       500\n",
      "\n",
      "    accuracy                           0.91      1000\n",
      "   macro avg       0.91      0.91      0.91      1000\n",
      "weighted avg       0.91      0.91      0.91      1000\n",
      "\n",
      "epoch: 64\n",
      "train: {'loss': 0.09944114109708203}\n",
      "train:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      4500\n",
      "           1       0.96      0.96      0.96      4500\n",
      "\n",
      "    accuracy                           0.96      9000\n",
      "   macro avg       0.96      0.96      0.96      9000\n",
      "weighted avg       0.96      0.96      0.96      9000\n",
      "\n",
      "val: {'loss': 0.2552933804690838}\n",
      "val:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.90      0.90       500\n",
      "           1       0.90      0.91      0.90       500\n",
      "\n",
      "    accuracy                           0.90      1000\n",
      "   macro avg       0.90      0.90      0.90      1000\n",
      "weighted avg       0.90      0.90      0.90      1000\n",
      "\n",
      "epoch: 65\n",
      "train: {'loss': 0.09582418907019827}\n",
      "train:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96      4500\n",
      "           1       0.97      0.96      0.96      4500\n",
      "\n",
      "    accuracy                           0.96      9000\n",
      "   macro avg       0.96      0.96      0.96      9000\n",
      "weighted avg       0.96      0.96      0.96      9000\n",
      "\n",
      "val: {'loss': 0.2537730149924755}\n",
      "val:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91       500\n",
      "           1       0.91      0.91      0.91       500\n",
      "\n",
      "    accuracy                           0.91      1000\n",
      "   macro avg       0.91      0.91      0.91      1000\n",
      "weighted avg       0.91      0.91      0.91      1000\n",
      "\n",
      "epoch: 66\n",
      "train: {'loss': 0.1041795044309563}\n",
      "train:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      4500\n",
      "           1       0.96      0.96      0.96      4500\n",
      "\n",
      "    accuracy                           0.96      9000\n",
      "   macro avg       0.96      0.96      0.96      9000\n",
      "weighted avg       0.96      0.96      0.96      9000\n",
      "\n",
      "val: {'loss': 0.25933822616934776}\n",
      "val:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.90      0.91       500\n",
      "           1       0.90      0.91      0.91       500\n",
      "\n",
      "    accuracy                           0.91      1000\n",
      "   macro avg       0.91      0.91      0.91      1000\n",
      "weighted avg       0.91      0.91      0.91      1000\n",
      "\n",
      "epoch: 67\n",
      "train: {'loss': 0.10103327625741561}\n",
      "train:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96      4500\n",
      "           1       0.97      0.96      0.96      4500\n",
      "\n",
      "    accuracy                           0.96      9000\n",
      "   macro avg       0.96      0.96      0.96      9000\n",
      "weighted avg       0.96      0.96      0.96      9000\n",
      "\n",
      "val: {'loss': 0.252937626093626}\n",
      "val:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.90      0.91       500\n",
      "           1       0.90      0.91      0.91       500\n",
      "\n",
      "    accuracy                           0.91      1000\n",
      "   macro avg       0.91      0.91      0.91      1000\n",
      "weighted avg       0.91      0.91      0.91      1000\n",
      "\n",
      "epoch: 68\n",
      "train: {'loss': 0.0971031216904521}\n",
      "train:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.97      4500\n",
      "           1       0.97      0.96      0.97      4500\n",
      "\n",
      "    accuracy                           0.97      9000\n",
      "   macro avg       0.97      0.97      0.97      9000\n",
      "weighted avg       0.97      0.97      0.97      9000\n",
      "\n",
      "val: {'loss': 0.25876113399863243}\n",
      "val:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.91      0.91       500\n",
      "           1       0.91      0.90      0.90       500\n",
      "\n",
      "    accuracy                           0.91      1000\n",
      "   macro avg       0.91      0.91      0.90      1000\n",
      "weighted avg       0.91      0.91      0.90      1000\n",
      "\n",
      "epoch: 69\n",
      "train: {'loss': 0.1008693306810326}\n",
      "train:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      4500\n",
      "           1       0.96      0.96      0.96      4500\n",
      "\n",
      "    accuracy                           0.96      9000\n",
      "   macro avg       0.96      0.96      0.96      9000\n",
      "weighted avg       0.96      0.96      0.96      9000\n",
      "\n",
      "val: {'loss': 0.2612393721938133}\n",
      "val:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.90      0.90       500\n",
      "           1       0.90      0.91      0.91       500\n",
      "\n",
      "    accuracy                           0.91      1000\n",
      "   macro avg       0.91      0.91      0.90      1000\n",
      "weighted avg       0.91      0.91      0.90      1000\n",
      "\n",
      "epoch: 70\n",
      "train: {'loss': 0.10173134930017921}\n",
      "train:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      4500\n",
      "           1       0.96      0.96      0.96      4500\n",
      "\n",
      "    accuracy                           0.96      9000\n",
      "   macro avg       0.96      0.96      0.96      9000\n",
      "weighted avg       0.96      0.96      0.96      9000\n",
      "\n",
      "val: {'loss': 0.25477050989866257}\n",
      "val:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.92      0.91       500\n",
      "           1       0.91      0.90      0.91       500\n",
      "\n",
      "    accuracy                           0.91      1000\n",
      "   macro avg       0.91      0.91      0.91      1000\n",
      "weighted avg       0.91      0.91      0.91      1000\n",
      "\n",
      "epoch: 71\n",
      "train: {'loss': 0.10135949403047562}\n",
      "train:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      4500\n",
      "           1       0.96      0.96      0.96      4500\n",
      "\n",
      "    accuracy                           0.96      9000\n",
      "   macro avg       0.96      0.96      0.96      9000\n",
      "weighted avg       0.96      0.96      0.96      9000\n",
      "\n",
      "val: {'loss': 0.2558618411421776}\n",
      "val:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91       500\n",
      "           1       0.91      0.91      0.91       500\n",
      "\n",
      "    accuracy                           0.91      1000\n",
      "   macro avg       0.91      0.91      0.91      1000\n",
      "weighted avg       0.91      0.91      0.91      1000\n",
      "\n",
      "epoch: 72\n",
      "train: {'loss': 0.10286120066626205}\n",
      "train:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      4500\n",
      "           1       0.96      0.96      0.96      4500\n",
      "\n",
      "    accuracy                           0.96      9000\n",
      "   macro avg       0.96      0.96      0.96      9000\n",
      "weighted avg       0.96      0.96      0.96      9000\n",
      "\n",
      "val: {'loss': 0.26254740729928017}\n",
      "val:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.90      0.90       500\n",
      "           1       0.90      0.91      0.91       500\n",
      "\n",
      "    accuracy                           0.91      1000\n",
      "   macro avg       0.91      0.91      0.90      1000\n",
      "weighted avg       0.91      0.91      0.90      1000\n",
      "\n",
      "epoch: 73\n",
      "train: {'loss': 0.09835305623710155}\n",
      "train:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      4500\n",
      "           1       0.96      0.96      0.96      4500\n",
      "\n",
      "    accuracy                           0.96      9000\n",
      "   macro avg       0.96      0.96      0.96      9000\n",
      "weighted avg       0.96      0.96      0.96      9000\n",
      "\n",
      "val: {'loss': 0.26914871484041214}\n",
      "val:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.90      0.90       500\n",
      "           1       0.90      0.91      0.90       500\n",
      "\n",
      "    accuracy                           0.90      1000\n",
      "   macro avg       0.90      0.90      0.90      1000\n",
      "weighted avg       0.90      0.90      0.90      1000\n",
      "\n",
      "epoch: 74\n",
      "train: {'loss': 0.10023810890399748}\n",
      "train:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      4500\n",
      "           1       0.96      0.96      0.96      4500\n",
      "\n",
      "    accuracy                           0.96      9000\n",
      "   macro avg       0.96      0.96      0.96      9000\n",
      "weighted avg       0.96      0.96      0.96      9000\n",
      "\n",
      "val: {'loss': 0.25827731564641}\n",
      "val:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.90      0.91       500\n",
      "           1       0.90      0.91      0.91       500\n",
      "\n",
      "    accuracy                           0.91      1000\n",
      "   macro avg       0.91      0.91      0.91      1000\n",
      "weighted avg       0.91      0.91      0.91      1000\n",
      "\n",
      "epoch: 75\n",
      "train: {'loss': 0.10451587920801507}\n",
      "train:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96      4500\n",
      "           1       0.97      0.96      0.96      4500\n",
      "\n",
      "    accuracy                           0.96      9000\n",
      "   macro avg       0.96      0.96      0.96      9000\n",
      "weighted avg       0.96      0.96      0.96      9000\n",
      "\n",
      "val: {'loss': 0.2567870765924454}\n",
      "val:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91       500\n",
      "           1       0.91      0.91      0.91       500\n",
      "\n",
      "    accuracy                           0.91      1000\n",
      "   macro avg       0.91      0.91      0.91      1000\n",
      "weighted avg       0.91      0.91      0.91      1000\n",
      "\n",
      "epoch: 76\n",
      "train: {'loss': 0.09289878089394835}\n",
      "train:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96      4500\n",
      "           1       0.97      0.96      0.96      4500\n",
      "\n",
      "    accuracy                           0.96      9000\n",
      "   macro avg       0.96      0.96      0.96      9000\n",
      "weighted avg       0.96      0.96      0.96      9000\n",
      "\n",
      "val: {'loss': 0.25578562542796135}\n",
      "val:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.90      0.90       500\n",
      "           1       0.90      0.91      0.91       500\n",
      "\n",
      "    accuracy                           0.91      1000\n",
      "   macro avg       0.91      0.91      0.90      1000\n",
      "weighted avg       0.91      0.91      0.90      1000\n",
      "\n",
      "Epoch    76: reducing learning rate of group 0 to 1.0000e-05.\n",
      "epoch: 77\n",
      "train: {'loss': 0.10075492639508513}\n",
      "train:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.97      4500\n",
      "           1       0.97      0.96      0.97      4500\n",
      "\n",
      "    accuracy                           0.97      9000\n",
      "   macro avg       0.97      0.97      0.97      9000\n",
      "weighted avg       0.97      0.97      0.97      9000\n",
      "\n",
      "val: {'loss': 0.2574364170432091}\n",
      "val:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91       500\n",
      "           1       0.91      0.91      0.91       500\n",
      "\n",
      "    accuracy                           0.91      1000\n",
      "   macro avg       0.91      0.91      0.91      1000\n",
      "weighted avg       0.91      0.91      0.91      1000\n",
      "\n",
      "epoch: 78\n",
      "train: {'loss': 0.11146997246477339}\n",
      "train:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96      4500\n",
      "           1       0.97      0.96      0.96      4500\n",
      "\n",
      "    accuracy                           0.96      9000\n",
      "   macro avg       0.96      0.96      0.96      9000\n",
      "weighted avg       0.96      0.96      0.96      9000\n",
      "\n",
      "val: {'loss': 0.26607246324419975}\n",
      "val:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.90      0.91       500\n",
      "           1       0.90      0.91      0.91       500\n",
      "\n",
      "    accuracy                           0.91      1000\n",
      "   macro avg       0.91      0.91      0.91      1000\n",
      "weighted avg       0.91      0.91      0.91      1000\n",
      "\n",
      "epoch: 79\n",
      "train: {'loss': 0.0938811091085275}\n",
      "train:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      4500\n",
      "           1       0.96      0.96      0.96      4500\n",
      "\n",
      "    accuracy                           0.96      9000\n",
      "   macro avg       0.96      0.96      0.96      9000\n",
      "weighted avg       0.96      0.96      0.96      9000\n",
      "\n",
      "val: {'loss': 0.25831829756498337}\n",
      "val:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.90      0.91       500\n",
      "           1       0.90      0.91      0.91       500\n",
      "\n",
      "    accuracy                           0.91      1000\n",
      "   macro avg       0.91      0.91      0.91      1000\n",
      "weighted avg       0.91      0.91      0.91      1000\n",
      "\n",
      "epoch: 80\n",
      "train: {'loss': 0.09508857855366336}\n",
      "train:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      4500\n",
      "           1       0.96      0.96      0.96      4500\n",
      "\n",
      "    accuracy                           0.96      9000\n",
      "   macro avg       0.96      0.96      0.96      9000\n",
      "weighted avg       0.96      0.96      0.96      9000\n",
      "\n",
      "val: {'loss': 0.2596971243619919}\n",
      "val:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91       500\n",
      "           1       0.91      0.91      0.91       500\n",
      "\n",
      "    accuracy                           0.91      1000\n",
      "   macro avg       0.91      0.91      0.91      1000\n",
      "weighted avg       0.91      0.91      0.91      1000\n",
      "\n",
      "epoch: 81\n",
      "train: {'loss': 0.10488923980544011}\n",
      "train:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96      4500\n",
      "           1       0.97      0.96      0.96      4500\n",
      "\n",
      "    accuracy                           0.96      9000\n",
      "   macro avg       0.96      0.96      0.96      9000\n",
      "weighted avg       0.96      0.96      0.96      9000\n",
      "\n",
      "val: {'loss': 0.26157569885253906}\n",
      "val:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91       500\n",
      "           1       0.91      0.91      0.91       500\n",
      "\n",
      "    accuracy                           0.91      1000\n",
      "   macro avg       0.91      0.91      0.91      1000\n",
      "weighted avg       0.91      0.91      0.91      1000\n",
      "\n",
      "epoch: 82\n",
      "train: {'loss': 0.09193969859431188}\n",
      "train:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.97      4500\n",
      "           1       0.97      0.96      0.97      4500\n",
      "\n",
      "    accuracy                           0.97      9000\n",
      "   macro avg       0.97      0.97      0.97      9000\n",
      "weighted avg       0.97      0.97      0.97      9000\n",
      "\n",
      "val: {'loss': 0.2588648088276386}\n",
      "val:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.90      0.91       500\n",
      "           1       0.90      0.92      0.91       500\n",
      "\n",
      "    accuracy                           0.91      1000\n",
      "   macro avg       0.91      0.91      0.91      1000\n",
      "weighted avg       0.91      0.91      0.91      1000\n",
      "\n",
      "epoch: 83\n",
      "train: {'loss': 0.09901957793368234}\n",
      "train:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.97      4500\n",
      "           1       0.97      0.96      0.96      4500\n",
      "\n",
      "    accuracy                           0.96      9000\n",
      "   macro avg       0.97      0.97      0.96      9000\n",
      "weighted avg       0.97      0.96      0.96      9000\n",
      "\n",
      "val: {'loss': 0.2611404210329056}\n",
      "val:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91       500\n",
      "           1       0.91      0.91      0.91       500\n",
      "\n",
      "    accuracy                           0.91      1000\n",
      "   macro avg       0.91      0.91      0.91      1000\n",
      "weighted avg       0.91      0.91      0.91      1000\n",
      "\n",
      "epoch: 84\n",
      "train: {'loss': 0.1095041577807731}\n",
      "train:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      4500\n",
      "           1       0.96      0.96      0.96      4500\n",
      "\n",
      "    accuracy                           0.96      9000\n",
      "   macro avg       0.96      0.96      0.96      9000\n",
      "weighted avg       0.96      0.96      0.96      9000\n",
      "\n",
      "val: {'loss': 0.2618696130812168}\n",
      "val:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.90      0.91       500\n",
      "           1       0.90      0.91      0.91       500\n",
      "\n",
      "    accuracy                           0.91      1000\n",
      "   macro avg       0.91      0.91      0.91      1000\n",
      "weighted avg       0.91      0.91      0.91      1000\n",
      "\n",
      "epoch: 85\n",
      "train: {'loss': 0.09644533166040976}\n",
      "train:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96      4500\n",
      "           1       0.97      0.96      0.96      4500\n",
      "\n",
      "    accuracy                           0.96      9000\n",
      "   macro avg       0.96      0.96      0.96      9000\n",
      "weighted avg       0.96      0.96      0.96      9000\n",
      "\n",
      "val: {'loss': 0.2577045075595379}\n",
      "val:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.90      0.91       500\n",
      "           1       0.90      0.91      0.91       500\n",
      "\n",
      "    accuracy                           0.91      1000\n",
      "   macro avg       0.91      0.91      0.91      1000\n",
      "weighted avg       0.91      0.91      0.91      1000\n",
      "\n",
      "epoch: 86\n",
      "train: {'loss': 0.10046484683536822}\n",
      "train:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      4500\n",
      "           1       0.96      0.96      0.96      4500\n",
      "\n",
      "    accuracy                           0.96      9000\n",
      "   macro avg       0.96      0.96      0.96      9000\n",
      "weighted avg       0.96      0.96      0.96      9000\n",
      "\n",
      "val: {'loss': 0.25960102304816246}\n",
      "val:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.90      0.90       500\n",
      "           1       0.90      0.91      0.91       500\n",
      "\n",
      "    accuracy                           0.91      1000\n",
      "   macro avg       0.91      0.91      0.90      1000\n",
      "weighted avg       0.91      0.91      0.90      1000\n",
      "\n",
      "epoch: 87\n",
      "train: {'loss': 0.09210902483512957}\n",
      "train:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      4500\n",
      "           1       0.96      0.96      0.96      4500\n",
      "\n",
      "    accuracy                           0.96      9000\n",
      "   macro avg       0.96      0.96      0.96      9000\n",
      "weighted avg       0.96      0.96      0.96      9000\n",
      "\n",
      "val: {'loss': 0.26366670429706573}\n",
      "val:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.90      0.91       500\n",
      "           1       0.90      0.91      0.91       500\n",
      "\n",
      "    accuracy                           0.91      1000\n",
      "   macro avg       0.91      0.91      0.91      1000\n",
      "weighted avg       0.91      0.91      0.91      1000\n",
      "\n",
      "epoch: 88\n",
      "train: {'loss': 0.10051741130236122}\n",
      "train:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      4500\n",
      "           1       0.96      0.96      0.96      4500\n",
      "\n",
      "    accuracy                           0.96      9000\n",
      "   macro avg       0.96      0.96      0.96      9000\n",
      "weighted avg       0.96      0.96      0.96      9000\n",
      "\n",
      "val: {'loss': 0.26478685811161995}\n",
      "val:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.90      0.91       500\n",
      "           1       0.90      0.91      0.91       500\n",
      "\n",
      "    accuracy                           0.91      1000\n",
      "   macro avg       0.91      0.91      0.91      1000\n",
      "weighted avg       0.91      0.91      0.91      1000\n",
      "\n",
      "epoch: 89\n",
      "train: {'loss': 0.09177340142842796}\n",
      "train:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97      4500\n",
      "           1       0.97      0.97      0.97      4500\n",
      "\n",
      "    accuracy                           0.97      9000\n",
      "   macro avg       0.97      0.97      0.97      9000\n",
      "weighted avg       0.97      0.97      0.97      9000\n",
      "\n",
      "val: {'loss': 0.2633233368396759}\n",
      "val:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.90      0.90       500\n",
      "           1       0.90      0.91      0.91       500\n",
      "\n",
      "    accuracy                           0.91      1000\n",
      "   macro avg       0.91      0.91      0.90      1000\n",
      "weighted avg       0.91      0.91      0.90      1000\n",
      "\n",
      "epoch: 90\n",
      "train: {'loss': 0.08486903306200272}\n",
      "train:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97      4500\n",
      "           1       0.97      0.97      0.97      4500\n",
      "\n",
      "    accuracy                           0.97      9000\n",
      "   macro avg       0.97      0.97      0.97      9000\n",
      "weighted avg       0.97      0.97      0.97      9000\n",
      "\n",
      "val: {'loss': 0.2565777190029621}\n",
      "val:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91       500\n",
      "           1       0.91      0.91      0.91       500\n",
      "\n",
      "    accuracy                           0.91      1000\n",
      "   macro avg       0.91      0.91      0.91      1000\n",
      "weighted avg       0.91      0.91      0.91      1000\n",
      "\n",
      "epoch: 91\n",
      "train: {'loss': 0.10169130677564277}\n",
      "train:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96      4500\n",
      "           1       0.97      0.96      0.96      4500\n",
      "\n",
      "    accuracy                           0.96      9000\n",
      "   macro avg       0.96      0.96      0.96      9000\n",
      "weighted avg       0.96      0.96      0.96      9000\n",
      "\n",
      "val: {'loss': 0.25222616270184517}\n",
      "val:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91       500\n",
      "           1       0.91      0.91      0.91       500\n",
      "\n",
      "    accuracy                           0.91      1000\n",
      "   macro avg       0.91      0.91      0.91      1000\n",
      "weighted avg       0.91      0.91      0.91      1000\n",
      "\n",
      "epoch: 92\n",
      "train: {'loss': 0.119994029816654}\n",
      "train:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      4500\n",
      "           1       0.96      0.96      0.96      4500\n",
      "\n",
      "    accuracy                           0.96      9000\n",
      "   macro avg       0.96      0.96      0.96      9000\n",
      "weighted avg       0.96      0.96      0.96      9000\n",
      "\n",
      "val: {'loss': 0.2628655843436718}\n",
      "val:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.90      0.91       500\n",
      "           1       0.90      0.91      0.91       500\n",
      "\n",
      "    accuracy                           0.91      1000\n",
      "   macro avg       0.91      0.91      0.91      1000\n",
      "weighted avg       0.91      0.91      0.91      1000\n",
      "\n",
      "epoch: 93\n",
      "train: {'loss': 0.1048432800711857}\n",
      "train:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      4500\n",
      "           1       0.96      0.96      0.96      4500\n",
      "\n",
      "    accuracy                           0.96      9000\n",
      "   macro avg       0.96      0.96      0.96      9000\n",
      "weighted avg       0.96      0.96      0.96      9000\n",
      "\n",
      "val: {'loss': 0.2571612372994423}\n",
      "val:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.92      0.91       500\n",
      "           1       0.92      0.90      0.91       500\n",
      "\n",
      "    accuracy                           0.91      1000\n",
      "   macro avg       0.91      0.91      0.91      1000\n",
      "weighted avg       0.91      0.91      0.91      1000\n",
      "\n",
      "Epoch    93: reducing learning rate of group 0 to 1.0000e-06.\n",
      "epoch: 94\n",
      "train: {'loss': 0.10110139432880613}\n",
      "train:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      4500\n",
      "           1       0.96      0.96      0.96      4500\n",
      "\n",
      "    accuracy                           0.96      9000\n",
      "   macro avg       0.96      0.96      0.96      9000\n",
      "weighted avg       0.96      0.96      0.96      9000\n",
      "\n",
      "val: {'loss': 0.2636190317571163}\n",
      "val:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.90      0.91       500\n",
      "           1       0.90      0.92      0.91       500\n",
      "\n",
      "    accuracy                           0.91      1000\n",
      "   macro avg       0.91      0.91      0.91      1000\n",
      "weighted avg       0.91      0.91      0.91      1000\n",
      "\n",
      "epoch: 95\n",
      "train: {'loss': 0.09828187121699254}\n",
      "train:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96      4500\n",
      "           1       0.97      0.96      0.96      4500\n",
      "\n",
      "    accuracy                           0.96      9000\n",
      "   macro avg       0.96      0.96      0.96      9000\n",
      "weighted avg       0.96      0.96      0.96      9000\n",
      "\n",
      "val: {'loss': 0.25769439339637756}\n",
      "val:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.90      0.90       500\n",
      "           1       0.90      0.91      0.91       500\n",
      "\n",
      "    accuracy                           0.91      1000\n",
      "   macro avg       0.91      0.91      0.90      1000\n",
      "weighted avg       0.91      0.91      0.90      1000\n",
      "\n",
      "epoch: 96\n",
      "train: {'loss': 0.0957770896040731}\n",
      "train:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.97      4500\n",
      "           1       0.97      0.96      0.97      4500\n",
      "\n",
      "    accuracy                           0.97      9000\n",
      "   macro avg       0.97      0.97      0.97      9000\n",
      "weighted avg       0.97      0.97      0.97      9000\n",
      "\n",
      "val: {'loss': 0.2636367119848728}\n",
      "val:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.90      0.91       500\n",
      "           1       0.90      0.91      0.91       500\n",
      "\n",
      "    accuracy                           0.91      1000\n",
      "   macro avg       0.91      0.91      0.91      1000\n",
      "weighted avg       0.91      0.91      0.91      1000\n",
      "\n",
      "epoch: 97\n",
      "train: {'loss': 0.09992586428092586}\n",
      "train:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96      4500\n",
      "           1       0.97      0.96      0.96      4500\n",
      "\n",
      "    accuracy                           0.96      9000\n",
      "   macro avg       0.96      0.96      0.96      9000\n",
      "weighted avg       0.96      0.96      0.96      9000\n",
      "\n",
      "val: {'loss': 0.26451586186885834}\n",
      "val:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.89      0.90       500\n",
      "           1       0.89      0.91      0.90       500\n",
      "\n",
      "    accuracy                           0.90      1000\n",
      "   macro avg       0.90      0.90      0.90      1000\n",
      "weighted avg       0.90      0.90      0.90      1000\n",
      "\n",
      "epoch: 98\n",
      "train: {'loss': 0.09090451761666271}\n",
      "train:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.97      4500\n",
      "           1       0.97      0.96      0.97      4500\n",
      "\n",
      "    accuracy                           0.97      9000\n",
      "   macro avg       0.97      0.97      0.97      9000\n",
      "weighted avg       0.97      0.97      0.97      9000\n",
      "\n",
      "val: {'loss': 0.2599875219166279}\n",
      "val:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.90      0.91       500\n",
      "           1       0.90      0.91      0.91       500\n",
      "\n",
      "    accuracy                           0.91      1000\n",
      "   macro avg       0.91      0.91      0.91      1000\n",
      "weighted avg       0.91      0.91      0.91      1000\n",
      "\n",
      "epoch: 99\n",
      "train: {'loss': 0.10548225748870108}\n",
      "train:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96      4500\n",
      "           1       0.97      0.96      0.96      4500\n",
      "\n",
      "    accuracy                           0.96      9000\n",
      "   macro avg       0.96      0.96      0.96      9000\n",
      "weighted avg       0.96      0.96      0.96      9000\n",
      "\n",
      "val: {'loss': 0.2642410881817341}\n",
      "val:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.90      0.91       500\n",
      "           1       0.90      0.91      0.91       500\n",
      "\n",
      "    accuracy                           0.91      1000\n",
      "   macro avg       0.91      0.91      0.91      1000\n",
      "weighted avg       0.91      0.91      0.91      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from inferno.utils.train_utils import AverageMeter\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "best_loss = np.inf\n",
    "for epoch in range(epochs):\n",
    "    print(f'epoch: {epoch}')\n",
    "    \n",
    "    model.train()\n",
    "    train_trackers = defaultdict(AverageMeter)\n",
    "    all_labels, all_preds = [], []\n",
    "    for image, label in train_dl:\n",
    "        images = image.to(device)\n",
    "        labels = label.to(device)\n",
    "        \n",
    "        logits = model(images)\n",
    "        loss = criterion(logits, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        all_labels.extend(label.numpy())\n",
    "        all_preds.extend(logits.argmax(dim=1).detach().cpu().numpy().tolist())\n",
    "        train_trackers['loss'].update(loss.item())\n",
    "        \n",
    "    print('train: {}'.format({k: v.avg for k, v in train_trackers.items()}))\n",
    "    print(f'train: {classification_report(y_true=all_labels, y_pred=all_preds)}')\n",
    "        \n",
    "    model.eval()\n",
    "    val_trackers = defaultdict(AverageMeter)\n",
    "    all_labels, all_preds = [], []\n",
    "    for image, label in val_dl:\n",
    "        images = image.to(device)\n",
    "        labels = label.to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            logits = model(images)\n",
    "            \n",
    "        loss = criterion(logits, labels)\n",
    "        \n",
    "        all_labels.extend(label.numpy())\n",
    "        all_preds.extend(logits.argmax(dim=1).detach().cpu().numpy().tolist())\n",
    "        val_trackers['loss'].update(loss.item())\n",
    "    \n",
    "    print('val: {}'.format({k: v.avg for k, v in val_trackers.items()}))\n",
    "    print(f'val: {classification_report(y_true=all_labels, y_pred=all_preds)}')\n",
    "    \n",
    "    val_loss = val_trackers['loss'].avg\n",
    "    scheduler.step(val_loss)\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        torch.save(model.state_dict(), 'best.pth')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9000\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "print(len(train_idx))\n",
    "print(len(val_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "model.load_state_dict(torch.load('best.pth'), strict=True)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = getattr(datasets, dataset_name)(root=data_root, train=False)\n",
    "class_labels = pd.Series(dataset.targets).map(idx_to_class)\n",
    "test_id_idx = np.where(class_labels.isin(np.unique(subset_labels)))[0]\n",
    "test_ood_idx = np.where(~class_labels.isin(np.unique(subset_labels)))[0]\n",
    "\n",
    "del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n",
      "8000\n"
     ]
    }
   ],
   "source": [
    "print(len(test_id_idx))\n",
    "print(len(test_ood_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id_dataset = getattr(datasets, dataset_name)(root=data_root, train=False, transform=val_xform, target_transform=target_transform)\n",
    "test_ood_dataset = getattr(datasets, dataset_name)(root=data_root, train=False, transform=val_xform)\n",
    "\n",
    "test_id_dl = DataLoader(test_id_dataset, batch_size=1, sampler=SubsetRandomSampler(test_id_idx), pin_memory=True, num_workers=2)\n",
    "test_ood_dl = DataLoader(test_ood_dataset, batch_size=1, sampler=SubsetRandomSampler(test_ood_idx), pin_memory=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from captum.attr import LayerConductance\n",
    "layers = ['layer1', 'layer2', 'layer3', 'layer4']\n",
    "\n",
    "lcs = {l: LayerConductance(model, getattr(model, l)) for l in layers}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### layer1\n",
      "(1000, 256)\n",
      "### layer2\n",
      "(1000, 512)\n",
      "### layer3\n",
      "(1000, 1024)\n",
      "### layer4\n",
      "(1000, 2048)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from torch.nn import functional as F\n",
    "\n",
    "data_loader = DataLoader(val_dataset, batch_size=1, sampler=SubsetRandomSampler(val_idx), pin_memory=True, num_workers=2)\n",
    "loader_name = 'val-id'\n",
    "\n",
    "for layer_name, lc in lcs.items():\n",
    "    attribution_matrix = None\n",
    "    val_labels = np.zeros((len(val_idx)), dtype='uint8')\n",
    "    print(f'### {layer_name}')\n",
    "    for ix, (images, labels) in enumerate(data_loader):\n",
    "        attribution = lc.attribute(images.to(device), target=labels[0])\n",
    "        pooled_attribution = F.adaptive(attribution, 1).cpu().detach().numpy().squeeze().astype('float16')\n",
    "        try:\n",
    "            attribution_matrix[ix, :] = pooled_attribution\n",
    "        except TypeError:\n",
    "            attribution_matrix = np.zeros((len(val_idx), len(pooled_attribution)), dtype='float16')\n",
    "            attribution_matrix[ix, :] = pooled_attribution\n",
    "        val_labels[ix] = labels.item()\n",
    "            \n",
    "    print(attribution_matrix.shape)\n",
    "    np.save(os.path.join('out', f'{loader_name}_{layer_name}.npy'), attribution_matrix)\n",
    "    np.save(os.path.join('out', f'{loader_name}_{layer_name}_labels.npy'), val_labels)\n",
    "    \n",
    "np.save(os.path.join('out', 'val-id_index.npy'), val_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# test-id\n",
      "### layer1\n",
      "(2, 2000, 256)\n",
      "### layer2\n",
      "(2, 2000, 512)\n",
      "### layer3\n",
      "(2, 2000, 1024)\n",
      "### layer4\n",
      "(2, 2000, 2048)\n",
      "# test-ood\n",
      "### layer1\n",
      "(2, 8000, 256)\n",
      "### layer2\n",
      "(2, 8000, 512)\n",
      "### layer3\n",
      "(2, 8000, 1024)\n",
      "### layer4\n",
      "(2, 8000, 2048)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from torch.nn import functional as F\n",
    "\n",
    "targets = [0, 1]\n",
    "for loader_name, data_loader, indices in zip(['test-id', 'test-ood'], [test_id_dl, test_ood_dl], [test_id_idx, test_ood_idx]):\n",
    "    print(f'# {loader_name}')\n",
    "    for layer_name, lc in lcs.items():\n",
    "        attribution_matrix = None\n",
    "        test_labels = np.zeros((len(indices)), dtype='uint8')\n",
    "        print(f'### {layer_name}')\n",
    "        for im_ix, (images, labels) in enumerate(data_loader):\n",
    "            for target in targets:\n",
    "                attribution = lc.attribute(images.to(device), target=target)\n",
    "                pooled_attribution = F.adaptive_avg_pool2d(attribution, 1).cpu().detach().numpy().squeeze().astype('float16')\n",
    "                try:\n",
    "                    attribution_matrix[target, im_ix, :] = pooled_attribution\n",
    "                except TypeError:\n",
    "                    attribution_matrix = np.zeros((len(targets), len(indices), len(pooled_attribution)), dtype='float16')\n",
    "                    attribution_matrix[target, im_ix, :] = pooled_attribution\n",
    "            test_labels[im_ix] = labels.item()\n",
    "\n",
    "        print(attribution_matrix.shape)\n",
    "        np.save(os.path.join('out', f'{loader_name}_{layer_name}.npy'), attribution_matrix)\n",
    "        np.save(os.path.join('out', f'{loader_name}_{layer_name}_labels.npy'), test_labels)\n",
    "    np.save(os.path.join('out', f'{loader_name}_index.npy'), indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2048, 1, 1])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attribution.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
