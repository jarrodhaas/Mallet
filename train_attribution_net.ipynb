{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class Network(nn.Module):\n",
    "    def __init__(self, num_hidden=2, dropout=0., in_feats=2048, num_classes=2):\n",
    "        super(TheFuckingSledge, self).__init__()\n",
    "        \n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.Conv1d(1, 8, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(8),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.block2 = nn.Sequential(\n",
    "            nn.Conv1d(8, 16, kernel_size=5, stride=2, padding=2),\n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.block3 = nn.Sequential(\n",
    "            nn.Conv1d(16, 16, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.avgpool = nn.AvgPool1d(2, stride=2)\n",
    "        self.block4 = nn.Sequential(\n",
    "            nn.Conv1d(16, 32, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.fc = nn.Linear(3840, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.block1(x.unsqueeze(1))\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = self.block4(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TheFuckingSledge(\n",
       "  (block1): Sequential(\n",
       "    (0): Conv1d(1, 8, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "    (1): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (block2): Sequential(\n",
       "    (0): Conv1d(8, 16, kernel_size=(5,), stride=(2,), padding=(2,))\n",
       "    (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (block3): Sequential(\n",
       "    (0): Conv1d(16, 16, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "    (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (avgpool): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))\n",
       "  (block4): Sequential(\n",
       "    (0): Conv1d(16, 32, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (fc): Linear(in_features=3840, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Network(dropout=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "class ConductanceDataset(Dataset):\n",
    "    def __init__(self, all_conductance: np.array, in_or_out: np.array, transform=None, target_transform=None):\n",
    "        super(ConductanceDataset, self).__init__()\n",
    "        \n",
    "        self.all_conductance = all_conductance\n",
    "        self.in_or_out = in_or_out\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.conductance)\n",
    "    \n",
    "    def __getitem__(self, ix):\n",
    "        conductance = self.all_conductance[ix]\n",
    "        label = self.in_or_out[ix]\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            conductance = self.transform(conductance)\n",
    "        if self.target_transform is not None:\n",
    "            label = self.target_transform(label)\n",
    "            \n",
    "        return {'ix': ix, 'conductance': conductance, 'label': label}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "CONDUCTANCE_DIR = './zf_net_conductance'\n",
    "ID_all_conductance = None\n",
    "OOD_all_class_conductances = None\n",
    "# layers = ['conv1', 'conv2', 'conv3', 'conv4']\n",
    "layers = ['conv1']\n",
    "\n",
    "for layer in layers:\n",
    "    ID_val_conductance = np.load(os.path.join(CONDUCTANCE_DIR, f'val_attri_{layer}_.npy')).astype('float32')\n",
    "\n",
    "    ID_test_class_conductances = np.load(os.path.join(CONDUCTANCE_DIR, f'test-id_attrib_{layer}.npy')).astype('float32')\n",
    "    ID_test_labels = np.load(os.path.join(CONDUCTANCE_DIR, f'test-id_labels_{layer}.npy')).astype('float32')\n",
    "    ID_test_conductance = np.concatenate((ID_test_class_conductances[0, ID_test_labels == 0], ID_test_class_conductances[1, ID_test_labels == 1]), axis=0)\n",
    "\n",
    "#     reorder_test_id = np.concatenate((np.where(is_a_hammer_two == 0)[0], np.where(is_a_hammer_two == 1)[0]))\n",
    "    \n",
    "    ID_conductance = np.concatenate((ID_val_conductance, ID_test_conductance), axis=0)\n",
    "    OOD_class_conductances = np.load(os.path.join(CONDUCTANCE_DIR, f'test-ood_attrib_{layer}.npy'))[0].astype('float32')\n",
    "    if ID_all_conductance is not None:\n",
    "        ID_all_conductance = np.concatenate((ID_all_conductance, ID_conductance), axis=-1)\n",
    "        OOD_all_class_conductances = np.concatenate((OOD_all_class_conductances, OOD_class_conductances), axis=-1)\n",
    "    else:\n",
    "        ID_all_conductance = ID_conductance\n",
    "        OOD_all_class_conductances = OOD_class_conductances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 96)\n",
      "(8000, 96)\n"
     ]
    }
   ],
   "source": [
    "ID_conductance = ID_all_conductance\n",
    "OOD_class_conductances = OOD_all_class_conductances\n",
    "print(ID_conductance.shape)\n",
    "print(OOD_class_conductances.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_distribution: \n",
      "hammers: 2300 400 300,\n",
      "other_tools: 2312 408 5280\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "idx = np.arange(len(ID_conductance))\n",
    "ID_train_idx, ID_test_idx = train_test_split(idx, test_size=0.1)\n",
    "ID_train_idx, ID_val_idx = train_test_split(ID_train_idx, test_size=0.1481)\n",
    "\n",
    "ID_train = ID_conductance[ID_train_idx]\n",
    "ID_val = ID_conductance[ID_val_idx]\n",
    "ID_test = ID_conductance[ID_test_idx]\n",
    "\n",
    "idx = np.arange(len(OOD_class_conductances))\n",
    "OOD_train_idx, OOD_test_idx = train_test_split(idx, test_size=0.66)\n",
    "OOD_train_idx, OOD_val_idx = train_test_split(OOD_train_idx, test_size=0.15)\n",
    "\n",
    "OOD_train = other_tools[OOD_train_idx]\n",
    "OOD_val = other_tools[other_tools_val_idx]\n",
    "OOD_test = other_tools[other_tools_test_idx]\n",
    "\n",
    "print(f\"data_distribution: \\n\"\n",
    "    f\"hammers: {len(hammers_train)} {len(hammers_val)} {len(hammers_test)},\\n\"\n",
    "    f\"other_tools: {len(other_tools_train)} {len(other_tools_val)} {len(other_tools_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "training_tools = np.concatenate((hammers_train, other_tools_train), axis=0)\n",
    "training_is_a_hammer = np.concatenate((np.ones(len(hammers_train)), np.zeros(len(other_tools_train))), axis=0).astype('int')\n",
    "\n",
    "training_hammersack = TheHammerSack(training_tools, training_is_a_hammer)\n",
    "training_hammersack = DataLoader(training_hammersack, batch_size=64, pin_memory=True, drop_last=False, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_tools = np.concatenate((hammers_val, other_tools_val), axis=0)\n",
    "validation_is_a_hammer = np.concatenate((np.ones(len(hammers_val)), np.zeros(len(other_tools_val))), axis=0).astype('int')\n",
    "\n",
    "validation_hammersack = TheHammerSack(validation_tools, validation_is_a_hammer)\n",
    "validation_hammersack = DataLoader(validation_hammersack, batch_size=64, pin_memory=True, drop_last=False, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import Adam, SGD\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "device = 'cuda:1'\n",
    "# the_hammer = TheHammer(dropout=0.5).to(device)\n",
    "the_hammer = TheFuckingSledge(dropout=0.5).to(device)\n",
    "criterion = CrossEntropyLoss(reduction='mean').to(device)\n",
    "optimizer = SGD(params=the_hammer.parameters(), lr=0.01, weight_decay=5e-5)\n",
    "scheduler = ReduceLROnPlateau(optimizer, patience=10, cooldown=10, factor=0.1, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "train: {'loss': 0.4314435700031176}\n",
      "train acc: 0.8185169124024284\n",
      "val: {'loss': 0.4623537648182649}\n",
      "val acc: 0.7586633663366337\n",
      "epoch: 1\n",
      "train: {'loss': 0.31096838475906685}\n",
      "train acc: 0.8809627059843885\n",
      "val: {'loss': 1.5230983525084762}\n",
      "val acc: 0.49504950495049505\n",
      "epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jhaas/Python_Envs36/default/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: {'loss': 0.27480545935973727}\n",
      "train acc: 0.8905030355594102\n",
      "val: {'loss': 0.24665581377652976}\n",
      "val acc: 0.8935643564356436\n",
      "epoch: 3\n",
      "train: {'loss': 0.2216960518327478}\n",
      "train acc: 0.9121856027753686\n",
      "val: {'loss': 0.3296647660720807}\n",
      "val acc: 0.8415841584158416\n",
      "epoch: 4\n",
      "train: {'loss': 0.19771912561295785}\n",
      "train acc: 0.9241110147441457\n",
      "val: {'loss': 0.20065097281566033}\n",
      "val acc: 0.926980198019802\n",
      "epoch: 5\n",
      "train: {'loss': 0.17600635326888464}\n",
      "train acc: 0.9371205550737207\n",
      "val: {'loss': 0.30204353682123697}\n",
      "val acc: 0.8663366336633663\n",
      "epoch: 6\n",
      "train: {'loss': 0.16132592726243686}\n",
      "train acc: 0.9386383347788378\n",
      "val: {'loss': 0.19129512860224798}\n",
      "val acc: 0.926980198019802\n",
      "epoch: 7\n",
      "train: {'loss': 0.145365282229773}\n",
      "train acc: 0.9507805724197745\n",
      "val: {'loss': 0.1975262162203972}\n",
      "val acc: 0.9047029702970297\n",
      "epoch: 8\n",
      "train: {'loss': 0.14184693389967695}\n",
      "train acc: 0.9466608846487424\n",
      "val: {'loss': 0.16186493864426246}\n",
      "val acc: 0.9356435643564357\n",
      "epoch: 9\n",
      "train: {'loss': 0.12768474537624072}\n",
      "train acc: 0.9568516912402428\n",
      "val: {'loss': 0.14884774501507098}\n",
      "val acc: 0.9492574257425742\n",
      "epoch: 10\n",
      "train: {'loss': 0.12277018615644272}\n",
      "train acc: 0.9585862966175195\n",
      "val: {'loss': 0.19987668598500583}\n",
      "val acc: 0.9084158415841584\n",
      "epoch: 11\n",
      "train: {'loss': 0.12173010868160691}\n",
      "train acc: 0.9533824804856895\n",
      "val: {'loss': 0.15028086877786195}\n",
      "val acc: 0.9381188118811881\n",
      "epoch: 12\n",
      "train: {'loss': 0.10940076359739043}\n",
      "train acc: 0.9629228100607112\n",
      "val: {'loss': 0.22819131770386145}\n",
      "val acc: 0.905940594059406\n",
      "epoch: 13\n",
      "train: {'loss': 0.10780523314255558}\n",
      "train acc: 0.9622723330442324\n",
      "val: {'loss': 0.1443669360417586}\n",
      "val acc: 0.9393564356435643\n",
      "epoch: 14\n",
      "train: {'loss': 0.11200861877774539}\n",
      "train acc: 0.9679098005203816\n",
      "val: {'loss': 0.2835184082818719}\n",
      "val acc: 0.8811881188118812\n",
      "epoch: 15\n",
      "train: {'loss': 0.12183820369513068}\n",
      "train acc: 0.9659583694709454\n",
      "val: {'loss': 1.02312917355448}\n",
      "val acc: 0.5792079207920792\n",
      "epoch: 16\n",
      "train: {'loss': 0.10670114655609}\n",
      "train acc: 0.9653078924544666\n",
      "val: {'loss': 0.1434980258345604}\n",
      "val acc: 0.948019801980198\n",
      "epoch: 17\n",
      "train: {'loss': 0.08791327940886967}\n",
      "train acc: 0.9718126626192541\n",
      "val: {'loss': 0.1434660445039089}\n",
      "val acc: 0.9455445544554455\n",
      "epoch: 18\n",
      "train: {'loss': 0.0958441638528076}\n",
      "train acc: 0.9720294882914137\n",
      "val: {'loss': 0.356216654754602}\n",
      "val acc: 0.8514851485148515\n",
      "epoch: 19\n",
      "train: {'loss': 0.09614139621796673}\n",
      "train acc: 0.9668256721595837\n",
      "val: {'loss': 0.14292395716676345}\n",
      "val acc: 0.9405940594059405\n",
      "epoch: 20\n",
      "train: {'loss': 0.08062241354013143}\n",
      "train acc: 0.9720294882914137\n",
      "val: {'loss': 0.1503258548103846}\n",
      "val acc: 0.9393564356435643\n",
      "epoch: 21\n",
      "train: {'loss': 0.07277863934534053}\n",
      "train acc: 0.9791847354726799\n",
      "val: {'loss': 0.13591907717860663}\n",
      "val acc: 0.948019801980198\n",
      "epoch: 22\n",
      "train: {'loss': 0.08270393896286618}\n",
      "train acc: 0.9748482220294883\n",
      "val: {'loss': 0.18842512942277467}\n",
      "val acc: 0.9245049504950495\n",
      "epoch: 23\n",
      "train: {'loss': 0.07981679971291594}\n",
      "train acc: 0.9748482220294883\n",
      "val: {'loss': 0.15333099348040727}\n",
      "val acc: 0.9467821782178217\n",
      "epoch: 24\n",
      "train: {'loss': 0.0771552102818881}\n",
      "train acc: 0.9763660017346054\n",
      "val: {'loss': 0.14462931310901275}\n",
      "val acc: 0.948019801980198\n",
      "epoch: 25\n",
      "train: {'loss': 0.06873248050576203}\n",
      "train acc: 0.9791847354726799\n",
      "val: {'loss': 0.14172688871622086}\n",
      "val acc: 0.9443069306930693\n",
      "epoch: 26\n",
      "train: {'loss': 0.06381400674581528}\n",
      "train acc: 0.9800520381613183\n",
      "val: {'loss': 0.13784568670850533}\n",
      "val acc: 0.943069306930693\n",
      "epoch: 27\n",
      "train: {'loss': 0.0697423012238251}\n",
      "train acc: 0.9796183868169991\n",
      "val: {'loss': 0.16137086471112874}\n",
      "val acc: 0.9331683168316832\n",
      "epoch: 28\n",
      "train: {'loss': 0.0695586589815682}\n",
      "train acc: 0.9791847354726799\n",
      "val: {'loss': 0.14129443982472786}\n",
      "val acc: 0.9455445544554455\n",
      "epoch: 29\n",
      "train: {'loss': 0.061783326330454386}\n",
      "train acc: 0.9824371205550737\n",
      "val: {'loss': 0.157640402420209}\n",
      "val acc: 0.9455445544554455\n",
      "epoch: 30\n",
      "train: {'loss': 0.05773179475473215}\n",
      "train acc: 0.9848222029488292\n",
      "val: {'loss': 0.13686232755963618}\n",
      "val acc: 0.9467821782178217\n",
      "epoch: 31\n",
      "train: {'loss': 0.05366119224425048}\n",
      "train acc: 0.985906331309627\n",
      "val: {'loss': 0.14739637621320212}\n",
      "val acc: 0.9467821782178217\n",
      "epoch: 32\n",
      "train: {'loss': 0.0521598011765578}\n",
      "train acc: 0.9867736339982653\n",
      "val: {'loss': 0.13696606227984795}\n",
      "val acc: 0.9443069306930693\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-03.\n",
      "epoch: 33\n",
      "train: {'loss': 0.04628308822898424}\n",
      "train acc: 0.9917606244579358\n",
      "val: {'loss': 0.1379894341986913}\n",
      "val acc: 0.9467821782178217\n",
      "epoch: 34\n",
      "train: {'loss': 0.04644605326019738}\n",
      "train acc: 0.9900260190806591\n",
      "val: {'loss': 0.13628620253159449}\n",
      "val acc: 0.9455445544554455\n",
      "epoch: 35\n",
      "train: {'loss': 0.05259191960555642}\n",
      "train acc: 0.9893755420641804\n",
      "val: {'loss': 0.1444290681527211}\n",
      "val acc: 0.9467821782178217\n",
      "epoch: 36\n",
      "train: {'loss': 0.047710790107511496}\n",
      "train acc: 0.9900260190806591\n",
      "val: {'loss': 0.1370758583339361}\n",
      "val acc: 0.9455445544554455\n",
      "epoch: 37\n",
      "train: {'loss': 0.04880746826529503}\n",
      "train acc: 0.9900260190806591\n",
      "val: {'loss': 0.13588057888241914}\n",
      "val acc: 0.948019801980198\n",
      "epoch: 38\n",
      "train: {'loss': 0.050969276602749955}\n",
      "train acc: 0.986990459670425\n",
      "val: {'loss': 0.13596493980059257}\n",
      "val acc: 0.9492574257425742\n",
      "epoch: 39\n",
      "train: {'loss': 0.046639438259274996}\n",
      "train acc: 0.988074588031223\n",
      "val: {'loss': 0.1358512949485045}\n",
      "val acc: 0.943069306930693\n",
      "epoch: 40\n",
      "train: {'loss': 0.047321288246814516}\n",
      "train acc: 0.988074588031223\n",
      "val: {'loss': 0.13917816229737723}\n",
      "val acc: 0.9443069306930693\n",
      "epoch: 41\n",
      "train: {'loss': 0.04711258357824528}\n",
      "train acc: 0.9911101474414571\n",
      "val: {'loss': 0.13796097212112868}\n",
      "val acc: 0.9443069306930693\n",
      "epoch: 42\n",
      "train: {'loss': 0.04689930819536317}\n",
      "train acc: 0.9893755420641804\n",
      "val: {'loss': 0.14040221847020662}\n",
      "val acc: 0.9455445544554455\n",
      "epoch: 43\n",
      "train: {'loss': 0.04535379171473523}\n",
      "train acc: 0.98959236773634\n",
      "val: {'loss': 0.1367927033167619}\n",
      "val acc: 0.9443069306930693\n",
      "epoch: 44\n",
      "train: {'loss': 0.045849197276242794}\n",
      "train acc: 0.9893755420641804\n",
      "val: {'loss': 0.13619973281255135}\n",
      "val acc: 0.9455445544554455\n",
      "epoch: 45\n",
      "train: {'loss': 0.04621466446974098}\n",
      "train acc: 0.9893755420641804\n",
      "val: {'loss': 0.13736042408989027}\n",
      "val acc: 0.9455445544554455\n",
      "epoch: 46\n",
      "train: {'loss': 0.046032339334487915}\n",
      "train acc: 0.9908933217692975\n",
      "val: {'loss': 0.1405767832811062}\n",
      "val acc: 0.9455445544554455\n",
      "epoch: 47\n",
      "train: {'loss': 0.04640159347694214}\n",
      "train acc: 0.9902428447528188\n",
      "val: {'loss': 0.14140787634712}\n",
      "val acc: 0.9455445544554455\n",
      "epoch: 48\n",
      "train: {'loss': 0.04895943423656568}\n",
      "train acc: 0.9900260190806591\n",
      "val: {'loss': 0.14731004604926476}\n",
      "val acc: 0.948019801980198\n",
      "epoch: 49\n",
      "train: {'loss': 0.044382153334070557}\n",
      "train acc: 0.9902428447528188\n",
      "val: {'loss': 0.1367324822797225}\n",
      "val acc: 0.948019801980198\n",
      "epoch: 50\n",
      "train: {'loss': 0.047557297328563584}\n",
      "train acc: 0.9898091934084996\n",
      "val: {'loss': 0.13706221517461997}\n",
      "val acc: 0.9443069306930693\n",
      "epoch: 51\n",
      "train: {'loss': 0.04548141573338884}\n",
      "train acc: 0.9902428447528188\n",
      "val: {'loss': 0.13804936036467552}\n",
      "val acc: 0.9455445544554455\n",
      "epoch: 52\n",
      "train: {'loss': 0.05117064284492437}\n",
      "train acc: 0.9898091934084996\n",
      "val: {'loss': 0.13987244923527425}\n",
      "val acc: 0.943069306930693\n",
      "epoch: 53\n",
      "train: {'loss': 0.045760982478522276}\n",
      "train acc: 0.9893755420641804\n",
      "val: {'loss': 0.13794404325576928}\n",
      "val acc: 0.9455445544554455\n",
      "Epoch    53: reducing learning rate of group 0 to 1.0000e-04.\n",
      "epoch: 54\n",
      "train: {'loss': 0.04532378743568512}\n",
      "train acc: 0.9908933217692975\n",
      "val: {'loss': 0.13768662225741607}\n",
      "val acc: 0.9455445544554455\n",
      "epoch: 55\n",
      "train: {'loss': 0.04318801674685658}\n",
      "train acc: 0.9921942758022549\n",
      "val: {'loss': 0.14261714942180193}\n",
      "val acc: 0.9455445544554455\n",
      "epoch: 56\n",
      "train: {'loss': 0.04527740823487713}\n",
      "train acc: 0.9900260190806591\n",
      "val: {'loss': 0.14040114988501257}\n",
      "val acc: 0.943069306930693\n",
      "epoch: 57\n",
      "train: {'loss': 0.0492440297025932}\n",
      "train acc: 0.9885082393755421\n",
      "val: {'loss': 0.14072217935552964}\n",
      "val acc: 0.9443069306930693\n",
      "epoch: 58\n",
      "train: {'loss': 0.043808460541783945}\n",
      "train acc: 0.9913269731136166\n",
      "val: {'loss': 0.13848671403068763}\n",
      "val acc: 0.9455445544554455\n",
      "epoch: 59\n",
      "train: {'loss': 0.04485374911088649}\n",
      "train acc: 0.9893755420641804\n",
      "val: {'loss': 0.13794957674466646}\n",
      "val acc: 0.9455445544554455\n",
      "epoch: 60\n",
      "train: {'loss': 0.04589754533124705}\n",
      "train acc: 0.9908933217692975\n",
      "val: {'loss': 0.14045664868675745}\n",
      "val acc: 0.943069306930693\n",
      "epoch: 61\n",
      "train: {'loss': 0.04563073477108184}\n",
      "train acc: 0.9908933217692975\n",
      "val: {'loss': 0.1379852042748378}\n",
      "val acc: 0.9455445544554455\n",
      "epoch: 62\n",
      "train: {'loss': 0.04591994222304593}\n",
      "train acc: 0.9904596704249783\n",
      "val: {'loss': 0.13914288408481157}\n",
      "val acc: 0.9455445544554455\n",
      "epoch: 63\n",
      "train: {'loss': 0.04346341413943327}\n",
      "train acc: 0.9919774501300954\n",
      "val: {'loss': 0.14267268433020666}\n",
      "val acc: 0.9455445544554455\n",
      "epoch: 64\n",
      "train: {'loss': 0.04385768155222886}\n",
      "train acc: 0.9900260190806591\n",
      "val: {'loss': 0.13802285864949226}\n",
      "val acc: 0.9467821782178217\n",
      "epoch: 65\n",
      "train: {'loss': 0.04440462607124897}\n",
      "train acc: 0.9917606244579358\n",
      "val: {'loss': 0.13931519710100615}\n",
      "val acc: 0.9443069306930693\n",
      "epoch: 66\n",
      "train: {'loss': 0.04436255180060047}\n",
      "train acc: 0.9924111014744146\n",
      "val: {'loss': 0.1386984595312522}\n",
      "val acc: 0.9443069306930693\n",
      "epoch: 67\n",
      "train: {'loss': 0.044421674887815565}\n",
      "train acc: 0.9908933217692975\n",
      "val: {'loss': 0.14122577670675057}\n",
      "val acc: 0.9443069306930693\n",
      "epoch: 68\n",
      "train: {'loss': 0.04416112946218824}\n",
      "train acc: 0.9919774501300954\n",
      "val: {'loss': 0.13954048489148801}\n",
      "val acc: 0.9443069306930693\n",
      "epoch: 69\n",
      "train: {'loss': 0.04322187952084901}\n",
      "train acc: 0.9913269731136166\n",
      "val: {'loss': 0.13718711728086838}\n",
      "val acc: 0.9455445544554455\n",
      "epoch: 70\n",
      "train: {'loss': 0.04408002233974738}\n",
      "train acc: 0.9908933217692975\n",
      "val: {'loss': 0.14164390615545785}\n",
      "val acc: 0.9443069306930693\n",
      "epoch: 71\n",
      "train: {'loss': 0.043586586104476285}\n",
      "train acc: 0.9906764960971379\n",
      "val: {'loss': 0.1383208024960298}\n",
      "val acc: 0.9443069306930693\n",
      "epoch: 72\n",
      "train: {'loss': 0.04345717314273527}\n",
      "train acc: 0.9913269731136166\n",
      "val: {'loss': 0.13881322426291612}\n",
      "val acc: 0.9455445544554455\n",
      "epoch: 73\n",
      "train: {'loss': 0.044623034457637836}\n",
      "train acc: 0.9919774501300954\n",
      "val: {'loss': 0.1388197885109828}\n",
      "val acc: 0.9443069306930693\n",
      "epoch: 74\n",
      "train: {'loss': 0.04454940239809556}\n",
      "train acc: 0.9906764960971379\n",
      "val: {'loss': 0.14106425213126036}\n",
      "val acc: 0.9455445544554455\n",
      "Epoch    74: reducing learning rate of group 0 to 1.0000e-05.\n",
      "epoch: 75\n",
      "train: {'loss': 0.04365856049914066}\n",
      "train acc: 0.9904596704249783\n",
      "val: {'loss': 0.13728643008149588}\n",
      "val acc: 0.9443069306930693\n",
      "epoch: 76\n",
      "train: {'loss': 0.04363127112745831}\n",
      "train acc: 0.9904596704249783\n",
      "val: {'loss': 0.1375515962449404}\n",
      "val acc: 0.9443069306930693\n",
      "epoch: 77\n",
      "train: {'loss': 0.04440179426376134}\n",
      "train acc: 0.9906764960971379\n",
      "val: {'loss': 0.1406776515337137}\n",
      "val acc: 0.9443069306930693\n",
      "epoch: 78\n",
      "train: {'loss': 0.044142400769338216}\n",
      "train acc: 0.9908933217692975\n",
      "val: {'loss': 0.14793409722355697}\n",
      "val acc: 0.9443069306930693\n",
      "epoch: 79\n",
      "train: {'loss': 0.04800123825975477}\n",
      "train acc: 0.98959236773634\n",
      "val: {'loss': 0.13838758348272398}\n",
      "val acc: 0.9455445544554455\n",
      "epoch: 80\n",
      "train: {'loss': 0.04667713521176005}\n",
      "train acc: 0.9898091934084996\n",
      "val: {'loss': 0.13755440425414306}\n",
      "val acc: 0.9455445544554455\n",
      "epoch: 81\n",
      "train: {'loss': 0.04409852026872439}\n",
      "train acc: 0.9902428447528188\n",
      "val: {'loss': 0.1374451480805874}\n",
      "val acc: 0.948019801980198\n",
      "epoch: 82\n",
      "train: {'loss': 0.04497133236225337}\n",
      "train acc: 0.9915437987857763\n",
      "val: {'loss': 0.14075661966433892}\n",
      "val acc: 0.9443069306930693\n",
      "epoch: 83\n",
      "train: {'loss': 0.04556172859076768}\n",
      "train acc: 0.9906764960971379\n",
      "val: {'loss': 0.13812482500305542}\n",
      "val acc: 0.9443069306930693\n",
      "epoch: 84\n",
      "train: {'loss': 0.04592171239934555}\n",
      "train acc: 0.9906764960971379\n",
      "val: {'loss': 0.13929655259618393}\n",
      "val acc: 0.9443069306930693\n",
      "epoch: 85\n",
      "train: {'loss': 0.04393936296899433}\n",
      "train acc: 0.9911101474414571\n",
      "val: {'loss': 0.14372815363682234}\n",
      "val acc: 0.9467821782178217\n",
      "epoch: 86\n",
      "train: {'loss': 0.04437954968785587}\n",
      "train acc: 0.9911101474414571\n",
      "val: {'loss': 0.14439901136434996}\n",
      "val acc: 0.9467821782178217\n",
      "epoch: 87\n",
      "train: {'loss': 0.04552748531409322}\n",
      "train acc: 0.9906764960971379\n",
      "val: {'loss': 0.16508264581744486}\n",
      "val acc: 0.943069306930693\n",
      "epoch: 88\n",
      "train: {'loss': 0.045486055697276165}\n",
      "train acc: 0.9906764960971379\n",
      "val: {'loss': 0.14350007560390693}\n",
      "val acc: 0.948019801980198\n",
      "epoch: 89\n",
      "train: {'loss': 0.044425489763691}\n",
      "train acc: 0.9900260190806591\n",
      "val: {'loss': 0.14145720320252272}\n",
      "val acc: 0.9455445544554455\n",
      "epoch: 90\n",
      "train: {'loss': 0.044353844699998424}\n",
      "train acc: 0.9908933217692975\n",
      "val: {'loss': 0.14881495099801284}\n",
      "val acc: 0.9455445544554455\n",
      "epoch: 91\n",
      "train: {'loss': 0.04420921553487647}\n",
      "train acc: 0.9908933217692975\n",
      "val: {'loss': 0.144606204273609}\n",
      "val acc: 0.9467821782178217\n",
      "epoch: 92\n",
      "train: {'loss': 0.044390394441681365}\n",
      "train acc: 0.9904596704249783\n",
      "val: {'loss': 0.13792142959741446}\n",
      "val acc: 0.9455445544554455\n",
      "epoch: 93\n",
      "train: {'loss': 0.04379118357670225}\n",
      "train acc: 0.9928447528187337\n",
      "val: {'loss': 0.1377178582434471}\n",
      "val acc: 0.9467821782178217\n",
      "epoch: 94\n",
      "train: {'loss': 0.04466753677554326}\n",
      "train acc: 0.9902428447528188\n",
      "val: {'loss': 0.21863381270892346}\n",
      "val acc: 0.9232673267326733\n",
      "epoch: 95\n",
      "train: {'loss': 0.045172074388661616}\n",
      "train acc: 0.9904596704249783\n",
      "val: {'loss': 0.13950447996075338}\n",
      "val acc: 0.9443069306930693\n",
      "Epoch    95: reducing learning rate of group 0 to 1.0000e-06.\n",
      "epoch: 96\n",
      "train: {'loss': 0.04352602214641767}\n",
      "train acc: 0.9915437987857763\n",
      "val: {'loss': 0.14486462336320144}\n",
      "val acc: 0.9467821782178217\n",
      "epoch: 97\n",
      "train: {'loss': 0.045285611145504535}\n",
      "train acc: 0.9904596704249783\n",
      "val: {'loss': 0.1457856446504593}\n",
      "val acc: 0.9467821782178217\n",
      "epoch: 98\n",
      "train: {'loss': 0.04588260719782277}\n",
      "train acc: 0.9900260190806591\n",
      "val: {'loss': 0.14370038589605919}\n",
      "val acc: 0.9467821782178217\n",
      "epoch: 99\n",
      "train: {'loss': 0.043910740938496916}\n",
      "train acc: 0.9906764960971379\n",
      "val: {'loss': 0.13918551086233213}\n",
      "val acc: 0.9443069306930693\n",
      "(array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
      "        15,  17,  18,  19,  20,  22,  23,  28,  31,  34,  42,  50,  53,\n",
      "        55,  68,  70,  73,  74,  75,  76,  77,  79,  80,  81,  82,  83,\n",
      "        84,  85,  86,  88,  91,  92,  93,  94,  95,  96,  97,  98,  99,\n",
      "       100]), array([271,  87, 166, 105,  31,  23,  18,  22,  10,   6,   2,   3,   2,\n",
      "         4,   1,   2,   1,   1,   2,   1,   1,   1,   1,   2,   1,   1,\n",
      "         1,   1,   1,   1,   1,   1,   1,   2,   1,   1,   1,   1,   1,\n",
      "         1,   1,   1,   3,   1,   1,   2,   2,   4,   2,   2,   4,   2,\n",
      "         3]))\n"
     ]
    }
   ],
   "source": [
    "from inferno.utils.train_utils import AverageMeter\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "best_loss = np.inf\n",
    "best_acc = 0\n",
    "times_it_was_wrong = np.zeros(len(validation_hammersack.dataset), dtype='int')\n",
    "for epoch in range(100):\n",
    "    print(f'epoch: {epoch}')\n",
    "    \n",
    "    the_hammer.train()\n",
    "    train_trackers = defaultdict(AverageMeter)\n",
    "    all_labels, all_preds = [], []\n",
    "    for sample in training_hammersack:\n",
    "        ix = sample['ix']\n",
    "        tools = sample['tool']\n",
    "        is_it_a_hammer = sample['is_it_a_hammer']\n",
    "        \n",
    "        tools = tools.to(device)\n",
    "        is_it_a_hammer = is_it_a_hammer.to(device)\n",
    "        \n",
    "        logits = the_hammer(tools)\n",
    "        loss = criterion(logits, is_it_a_hammer)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        all_labels.extend(is_it_a_hammer.cpu().detach().numpy().tolist())\n",
    "        all_preds.extend(logits.argmax(dim=1).detach().cpu().numpy().tolist())\n",
    "        train_trackers['loss'].update(loss.item())\n",
    "        \n",
    "    print('train: {}'.format({k: v.avg for k, v in train_trackers.items()}))\n",
    "    print(f'train acc: {classification_report(y_true=all_labels, y_pred=all_preds, output_dict=True)[\"accuracy\"]}')\n",
    "        \n",
    "    the_hammer.eval()\n",
    "    val_trackers = defaultdict(AverageMeter)\n",
    "    all_labels, all_preds = [], []\n",
    "    for sample in validation_hammersack:\n",
    "        ix = sample['ix']\n",
    "        tools = sample['tool']\n",
    "        is_it_a_hammer = sample['is_it_a_hammer']  \n",
    "          \n",
    "        tools = tools.to(device)\n",
    "        is_it_a_hammer = is_it_a_hammer.to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            logits = the_hammer(tools)\n",
    "          \n",
    "        preds = logits.argmax(dim=1)\n",
    "        wrong_mask = (preds != is_it_a_hammer)\n",
    "        times_it_was_wrong[ix.numpy()[wrong_mask.cpu().numpy()]] += 1\n",
    "            \n",
    "        loss = criterion(logits, is_it_a_hammer)\n",
    "        \n",
    "        all_labels.extend(is_it_a_hammer.cpu().detach().numpy().tolist())\n",
    "        all_preds.extend(logits.argmax(dim=1).detach().cpu().numpy().tolist())\n",
    "        val_trackers['loss'].update(loss.item())\n",
    "    \n",
    "    print('val: {}'.format({k: v.avg for k, v in val_trackers.items()}))\n",
    "    val_acc = classification_report(y_true=all_labels, y_pred=all_preds, output_dict=True)[\"accuracy\"]\n",
    "    print(f'val acc: {val_acc}')\n",
    "    \n",
    "    val_loss = val_trackers['loss'].avg\n",
    "    scheduler.step(val_loss)\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        torch.save(the_hammer.state_dict(), 'sledge_best.pth')\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "\n",
    "print(np.unique(times_it_was_wrong, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3ed1557a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.bar(range(len(times_it_was_wrong)), times_it_was_wrong)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1358512949485045"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9492574257425742"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10\n",
    "top_k_idx = np.argpartition(times_it_was_wrong, -k)[-k:]\n",
    "\n",
    "top_k_id_idx = top_k_idx[top_k_idx < len(hammers_val_idx)]\n",
    "top_k_ood_idx = top_k_idx[top_k_idx >= len(hammers_val_idx)] - len(hammers_val_idx)\n",
    "\n",
    "val_id_indices = hammers_val_idx\n",
    "val_ood_indices = other_tools_val_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1395 1207]\n",
      "[7881 6770 4582 6143 6918 2254 5661 4150]\n"
     ]
    }
   ],
   "source": [
    "print(val_id_indices[top_k_id_idx])\n",
    "print(val_ood_indices[top_k_ood_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "val_id_image_index = np.concatenate(\n",
    "    (np.load(os.path.join('out', 'val-id_index.npy')),\n",
    "     np.load(os.path.join('out', 'test-id_index.npy')))\n",
    ")[val_id_indices[top_k_id_idx]]\n",
    "val_ood_image_index = np.load(os.path.join('out', 'test-ood_index.npy'))[val_ood_indices[top_k_ood_idx]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1958,  964])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_id_image_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9853, 8446, 5739, 7668, 8637, 2817, 7074, 5181])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_ood_image_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets\n",
    "\n",
    "dataset_name = 'CIFAR10'\n",
    "data_root = './data'\n",
    "dataset = getattr(datasets, dataset_name)(root=data_root, train=True, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<PIL.Image.Image image mode=RGB size=32x32 at 0x7F3E4116CBA8>, 3)\n",
      "(<PIL.Image.Image image mode=RGB size=32x32 at 0x7F3E4116CC18>, 9)\n"
     ]
    }
   ],
   "source": [
    "for ix in val_id_image_index:\n",
    "    print(dataset[ix])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<PIL.Image.Image image mode=RGB size=32x32 at 0x7F3E41175320>, 0)\n",
      "(<PIL.Image.Image image mode=RGB size=32x32 at 0x7F3E41175390>, 6)\n",
      "(<PIL.Image.Image image mode=RGB size=32x32 at 0x7F3E41175320>, 4)\n",
      "(<PIL.Image.Image image mode=RGB size=32x32 at 0x7F3E41175390>, 8)\n",
      "(<PIL.Image.Image image mode=RGB size=32x32 at 0x7F3E41175320>, 8)\n",
      "(<PIL.Image.Image image mode=RGB size=32x32 at 0x7F3E41175390>, 8)\n",
      "(<PIL.Image.Image image mode=RGB size=32x32 at 0x7F3E41175320>, 2)\n",
      "(<PIL.Image.Image image mode=RGB size=32x32 at 0x7F3E41175390>, 1)\n"
     ]
    }
   ],
   "source": [
    "for ix in val_ood_image_index:\n",
    "    print(dataset[ix])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
